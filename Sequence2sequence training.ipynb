{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Sequence to Sequence Learning with Neural Networks* in PyTorch\n",
    "\n",
    "Encoder-decoder sequence to sequence RNN implementation based on 2014 publication:\n",
    "\n",
    "**Sequence to Sequence Learning with Neural Networks** - Ilya Sutskever, Oriol Vinyals, Quoc V. Le\n",
    "\n",
    "https://arxiv.org/abs/1409.3215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In the project files(PyTorch dataset implementation fra_eng_dataset.py) I use small toy dataset(170K sentences) in which can be found in the project files in fra-eng folder. But for this experiment I will try to use **WMT'14 English-German** dataset (4.5M sentences)\n",
    "\n",
    "The dataset can be found here:\n",
    "https://nlp.stanford.edu/projects/nmt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "\n",
    "\n",
    "RNN_LAYERS = 4\n",
    "RNN_HIDDEN_SIZE = 1024\n",
    "IN_EMBEDDING_SIZE = 256\n",
    "OUT_EMBEDDING_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "MAXMAX_SENTENCE_LEN = 50\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_dictionary(text_corpus_path, top_n = 50000):\n",
    "\n",
    "    print(f\"Creating top dictionary from: {text_corpus_path}..\")\n",
    "    \n",
    "    last_token_idx = 0\n",
    "    token_dict = dict()\n",
    "    token_counts_list = []\n",
    "    token_idx_to_token = []\n",
    "    \n",
    "    with open(text_corpus_path, \"r\", encoding='utf-8') as f:\n",
    "        \n",
    "        for idx, line in enumerate(f.readlines()):\n",
    "            \n",
    "            if (idx+1)% 500000 == 0:\n",
    "                print(f\"Processed {idx+1} lines\")\n",
    "\n",
    "            line = line.replace('##AT##', '')\n",
    "            token_list = word_tokenize(line)\n",
    "            for token in token_list:\n",
    "                token = token.lower()\n",
    "                if token not in token_dict:\n",
    "                    token_dict[token] = last_token_idx\n",
    "                    token_idx_to_token.append(token)\n",
    "                    token_counts_list.append((0,last_token_idx))\n",
    "                    last_token_idx += 1\n",
    "\n",
    "                token_idx = token_dict[token]\n",
    "                count, _ = token_counts_list[token_idx]\n",
    "                token_counts_list[token_idx] = (count+1,token_idx)\n",
    "                \n",
    "    token_counts_list = sorted(token_counts_list, reverse=True)\n",
    "    \n",
    "    top_token_list = []\n",
    "    \n",
    "    for idx, (count, token_idx) in enumerate(token_counts_list):\n",
    "        top_token_list.append(token_idx_to_token[token_idx])\n",
    "        \n",
    "        if idx > top_n:\n",
    "            break\n",
    "    \n",
    "    return top_token_list\n",
    "        \n",
    "\n",
    "\n",
    "class WMT14_en_de_Dataset(Dataset):\n",
    "    def __init__(self, data_source_path = 'wmt14_en_de'):\n",
    "        super().__init__()\n",
    "        \n",
    "        processed_data_path = \"processed_data.pkl\"\n",
    "        top_en_tokens_path = \"top_en_tokens.pkl\"\n",
    "        top_de_tokens_path = \"top_de_tokens.pkl\"\n",
    "        \n",
    "        self.sentence_list = []\n",
    "        \n",
    "        self.en_token_dict = dict()\n",
    "        self.en_token_dict['<PAD>'] = 0\n",
    "        self.en_token_dict['<EOS>'] = 1\n",
    "        self.en_token_dict['<UNK>'] = 2\n",
    "        self.en_last_token_idx = 2\n",
    "        self.en_token_idx_to_text = ['<PAD>', '<EOS>', '<UNK>']\n",
    "        \n",
    "        self.de_token_dict = dict()\n",
    "        self.de_token_dict['<PAD>'] = 0\n",
    "        self.de_token_dict['<EOS>'] = 1\n",
    "        self.de_token_dict['<UNK>'] = 2\n",
    "        self.de_last_token_idx = 2\n",
    "        self.de_token_idx_to_text = ['<PAD>', '<EOS>', '<UNK>']\n",
    "        \n",
    "        \n",
    "        if os.path.exists(processed_data_path):\n",
    "            with open(processed_data_path, 'rb') as f:\n",
    "                pickle_data = pickle.load(f)\n",
    "                self.sentence_list = pickle_data['sentence_list']\n",
    "                self.en_last_token_idx = pickle_data['en_last_token_idx']\n",
    "                self.de_last_token_idx = pickle_data['de_last_token_idx']\n",
    "                self.en_token_idx_to_text = pickle_data['en_token_idx_to_text']\n",
    "                self.de_token_idx_to_text = pickle_data['de_token_idx_to_text']\n",
    "        else:\n",
    "        \n",
    "            en_sentences_path = os.path.join(data_source_path, \"train.en\")\n",
    "            de_sentences_path = os.path.join(data_source_path, \"train.de\")\n",
    "            \n",
    "            if os.path.exists(top_en_tokens_path):\n",
    "                with open(top_en_tokens_path, \"rb\") as f:\n",
    "                    top_en_tokens = pickle.load(f)\n",
    "            else:\n",
    "                top_en_tokens = get_top_dictionary(en_sentences_path)\n",
    "                with open(top_en_tokens_path, \"wb\") as f:\n",
    "                    pickle.dump(top_en_tokens, f)\n",
    "            \n",
    "            \n",
    "            for token in top_en_tokens:\n",
    "                self.en_last_token_idx += 1\n",
    "                self.en_token_dict[token] = self.en_last_token_idx\n",
    "                self.en_token_idx_to_text.append(token)\n",
    "                \n",
    " \n",
    "            if os.path.exists(top_de_tokens_path):\n",
    "                with open(top_de_tokens_path, \"rb\") as f:\n",
    "                    top_de_tokens = pickle.load(f)\n",
    "            else:\n",
    "                top_de_tokens = get_top_dictionary(de_sentences_path)\n",
    "                with open(top_de_tokens_path, \"wb\") as f:\n",
    "                    pickle.dump(top_de_tokens, f)\n",
    "            \n",
    "            for token in top_de_tokens:\n",
    "                self.de_last_token_idx += 1\n",
    "                self.de_token_dict[token] = self.de_last_token_idx\n",
    "                self.de_token_idx_to_text.append(token)         \n",
    "                    \n",
    "            \n",
    "            with open(de_sentences_path, \"r\", encoding='utf-8') as de_f:\n",
    "                with open(en_sentences_path, \"r\", encoding='utf-8') as en_f:\n",
    "                    \n",
    "                    print(\"Creating sentences from {de_sentences_path} and {en_sentences_path} coropuses\")\n",
    "                    \n",
    "                    for idx, (de_sentence, en_sentence) in enumerate(zip(de_f.readlines(), en_f.readlines())):\n",
    "                        \n",
    "                        if (idx+1)%500000 == 0:\n",
    "                            print(f\"Processed {idx+1} lines\")\n",
    "                            \n",
    "                        de_sentence = de_sentence.replace('##AT##', '')\n",
    "                        en_sentence = en_sentence.replace('##AT##', '')\n",
    "                        \n",
    "                        en_token_sentence = []\n",
    "                        de_token_sentence = []\n",
    "\n",
    "                        en_token_list = word_tokenize(en_sentence)\n",
    "                        for token in en_token_list:\n",
    "                            token = token.lower()\n",
    "                            if token in self.en_token_dict:\n",
    "                                token_idx = self.en_token_dict[token]\n",
    "                            else:\n",
    "                                token_idx = self.en_token_dict['<UNK>']\n",
    "                                \n",
    "                            en_token_sentence.append(token_idx)\n",
    "\n",
    "                        en_token_sentence.append(self.en_token_dict['<EOS>'])\n",
    "\n",
    "                        de_token_list = word_tokenize(de_sentence)\n",
    "                        for token in de_token_list:\n",
    "                            token = token.lower()\n",
    "                            if token in self.de_token_dict:\n",
    "                                token_idx = self.de_token_dict[token]\n",
    "                            else:\n",
    "                                token_idx = self.de_token_dict['<UNK>']\n",
    "                                    \n",
    "\n",
    "                            de_token_sentence.append(token_idx)\n",
    "\n",
    "                        de_token_sentence.append(self.de_token_dict['<EOS>'])\n",
    "\n",
    "                        self.sentence_list.append(\n",
    "                            dict(\n",
    "                                en = en_token_sentence,\n",
    "                                de = de_token_sentence\n",
    "                            ))\n",
    "                        \n",
    "            with open(processed_data_path, \"wb\") as f:\n",
    "                pickle_processed_data = dict(\n",
    "                    sentence_list = self.sentence_list,\n",
    "                    en_last_token_idx = self.en_last_token_idx,\n",
    "                    de_last_token_idx = self.de_last_token_idx,\n",
    "                    en_token_idx_to_text = self.en_token_idx_to_text,\n",
    "                    de_token_idx_to_text = self.de_token_idx_to_text\n",
    "                )\n",
    "                pickle.dump(pickle_processed_data, f)\n",
    "            \n",
    "    def get_en_dict_size(self):\n",
    "        return self.en_last_token_idx + 1\n",
    "        \n",
    "    def get_de_dict_size(self):\n",
    "        return self.de_last_token_idx + 1\n",
    "    \n",
    "    def get_de_eos_code(self):\n",
    "        return self.de_token_dict['<EOS>']\n",
    "    \n",
    "    def get_en_eos_code(self):\n",
    "        return self.en_token_dict['<EOS>']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentence_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ret = dict()\n",
    "        for key in self.sentence_list[item]:\n",
    "            ret[key] = torch.tensor(self.sentence_list[item][key])\n",
    "        return ret\n",
    "\n",
    "\n",
    "def en_de_dataset_collate(data):\n",
    "\n",
    "    en_sentences = []\n",
    "    en_sentence_lens = []\n",
    "    de_sentences = []\n",
    "    de_sentence_lens = []\n",
    "    \n",
    "    en_sentences_sorted = []\n",
    "    en_sentence_lens_sorted = []\n",
    "    de_sentences_sorted = []\n",
    "    de_sentence_lens_sorted = []\n",
    "    \n",
    "    for s in data:\n",
    "        \n",
    "        sent = s['en'][0:MAXMAX_SENTENCE_LEN]\n",
    "        en_sentences.append(sent.unsqueeze(dim=1))\n",
    "        en_sentence_lens.append(len(sent))\n",
    "        \n",
    "        sent = s['de'][0:MAXMAX_SENTENCE_LEN]\n",
    "        de_sentences.append(sent.unsqueeze(dim=1))\n",
    "        de_sentence_lens.append(len(sent))\n",
    "\n",
    "    #Rearrange everything by de sentence lens\n",
    "    sort_idxes = np.argsort(np.array(de_sentence_lens))[::-1]\n",
    "    for idx in sort_idxes:\n",
    "        en_sentences_sorted.append(en_sentences[idx])\n",
    "        en_sentence_lens_sorted.append(en_sentence_lens[idx])\n",
    "        de_sentences_sorted.append(de_sentences[idx])\n",
    "        de_sentence_lens_sorted.append(de_sentence_lens[idx])\n",
    "    \n",
    "    return dict(\n",
    "        en_sentences = en_sentences_sorted,\n",
    "        en_lens = en_sentence_lens_sorted,\n",
    "        de_sentences = de_sentences_sorted,\n",
    "        de_lens = de_sentence_lens_sorted\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_encoder_model(nn.Module):\n",
    "    def __init__(self, in_dict_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dict_size = in_dict_size\n",
    "\n",
    "        self.embedding = nn.Linear(\n",
    "            in_dict_size, \n",
    "            IN_EMBEDDING_SIZE)\n",
    "        \n",
    "        \n",
    "        self.hidden = None \n",
    "        self.cell = None\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = IN_EMBEDDING_SIZE,\n",
    "            hidden_size = RNN_HIDDEN_SIZE,\n",
    "            num_layers = RNN_LAYERS\n",
    "        )\n",
    "        \n",
    "    def init_hidden_and_cell(self):\n",
    "        self.hidden = torch.zeros(RNN_LAYERS, BATCH_SIZE, RNN_HIDDEN_SIZE).to(device)\n",
    "        self.cell = torch.zeros(RNN_LAYERS, BATCH_SIZE, RNN_HIDDEN_SIZE).to(device)\n",
    "    \n",
    "    def get_hidden_and_cell(self):\n",
    "        return self.hidden, self.cell\n",
    "    \n",
    "    def forward(self, x):\n",
    "        padded_sent_one_hot, sent_lens = x\n",
    "        padded_sent_emb = self.embedding.forward(padded_sent_one_hot)\n",
    "        packed = pack_padded_sequence(padded_sent_emb, sent_lens)\n",
    "        packed, (self.hidden, self.cell) = self.rnn.forward(packed, (self.hidden,self.cell))\n",
    "        padded, sent_lens = pad_packed_sequence(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_decoder_model(nn.Module):\n",
    "    def __init__(self, out_dict_size):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.in_embedding = nn.Linear(\n",
    "            in_features=out_dict_size,\n",
    "            out_features=IN_EMBEDDING_SIZE\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = IN_EMBEDDING_SIZE,\n",
    "            hidden_size = RNN_HIDDEN_SIZE,\n",
    "            num_layers = RNN_LAYERS\n",
    "        )\n",
    "\n",
    "        self.rnn_to_embedding = nn.Linear(\n",
    "            in_features = RNN_HIDDEN_SIZE,\n",
    "            out_features = OUT_EMBEDDING_SIZE\n",
    "        )\n",
    "\n",
    "        self.embedding_to_logit = nn.Linear(\n",
    "            in_features = OUT_EMBEDDING_SIZE, \n",
    "            out_features = out_dict_size\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def init_hidden_and_cell(self, hidden, cell):\n",
    "        self.hidden = hidden\n",
    "        self.cell = cell\n",
    "    \n",
    "    \n",
    "    def forward(self, out_eos_code, out_dict_size, max_sentence_len):\n",
    "        batch_size = self.hidden.shape[1]\n",
    "        prev_outp = (torch.ones(1, batch_size, 1) * out_eos_code).long()\n",
    "        prev_outp = prev_outp.to(device)\n",
    "        \n",
    "        all_outp_prob = []\n",
    "        \n",
    "        for timestep in range(max_sentence_len):\n",
    "            \n",
    "            prev_outp_one_hot = torch.zeros(prev_outp.shape[0], prev_outp.shape[1], out_dict_size).to(device)\n",
    "            prev_outp_one_hot = prev_outp_one_hot.scatter_(2,prev_outp.data,1)\n",
    "            \n",
    "            prev_outp_in_emb = self.in_embedding(prev_outp_one_hot)\n",
    "         \n",
    "            cur_outp_hid, (self.hidden, self.cell) = self.rnn.forward(prev_outp_in_emb, (self.hidden, self.cell))\n",
    "            cur_outp_emb = self.rnn_to_embedding.forward(cur_outp_hid)\n",
    "            cur_outp_logits = self.embedding_to_logit(cur_outp_emb)\n",
    "            cur_outp_prob = self.softmax(cur_outp_logits)\n",
    "            all_outp_prob.append(cur_outp_prob)\n",
    "            \n",
    "            prev_outp = torch.argmax(cur_outp_prob.detach().data.to(device), dim=2, keepdim=True)\n",
    "        \n",
    "        all_outp_prob_tensor = torch.cat(all_outp_prob, dim=0)\n",
    "    \n",
    "        return all_outp_prob_tensor\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WMT14_en_de_Dataset()\n",
    "sentences_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=en_de_dataset_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(in_sentence_list, out_sentence_list, pred_tensor, num_batches):\n",
    "    \n",
    "    sentence_prediction_samples_path = 'sentence_predictions.text'\n",
    "    \n",
    "    print(f\"Printing sample predictions after {num_batches} batches in {sentence_prediction_samples_path}\")\n",
    "    \n",
    "    with open(sentence_prediction_samples_path, \"a\") as f:\n",
    "\n",
    "        for i in range(3):\n",
    "            f.write('='*50 + '\\n')\n",
    "            \n",
    "        f.write(f\"Sample predictions after {num_batches} batches \\n\\n\")\n",
    "              \n",
    "        in_token_to_text = dataset.de_token_idx_to_text\n",
    "        out_token_to_text = dataset.en_token_idx_to_text\n",
    "\n",
    "        for s in range(min(len(in_sentence_list),50)):\n",
    "\n",
    "            in_sent_text = []\n",
    "            for in_token in in_sentence_list[s].squeeze():\n",
    "                in_sent_text.append(in_token_to_text[in_token])\n",
    "\n",
    "            f.write(f\"\\nGerman sentence is: {' '.join(in_sent_text)} \\n\")\n",
    "\n",
    "            out_sent_text = []\n",
    "\n",
    "            for out_token in out_sentence_list[s].squeeze():\n",
    "                  out_sent_text.append(out_token_to_text[out_token])\n",
    "            f.write(f\"English sentence is: {' '.join(out_sent_text)}\\n\")\n",
    "\n",
    "            pred_sent_text = []\n",
    "            for ts in range(pred_tensor.shape[0]):\n",
    "                pred_token = torch.argmax(pred_tensor[ts, s,:]).data\n",
    "                pred_sent_text.append(out_token_to_text[pred_token])\n",
    "\n",
    "                if pred_token == dataset.get_en_eos_code():\n",
    "                    break\n",
    "            f.write(f\"Translated English sentence is: {' '.join(pred_sent_text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_encoder = RNN_encoder_model(dataset.get_de_dict_size()).to(device)\n",
    "rnn_decoder = RNN_decoder_model(dataset.get_en_dict_size()).to(device)\n",
    "\n",
    "trained_encoder_path = None\n",
    "trained_decoder_path = None\n",
    "\n",
    "trained_encoder_path = 'models/encoder_wmt14_de_en_3nd.pt'\n",
    "trained_decoder_path = 'models/decoder_wmt14_de_en_3nd.pt'\n",
    "\n",
    "if os.path.exists(trained_encoder_path):\n",
    "    rnn_encoder.load_state_dict(torch.load(trained_encoder_path))\n",
    "if os.path.exists(trained_decoder_path):\n",
    "    rnn_decoder.load_state_dict(torch.load(trained_decoder_path))\n",
    "\n",
    "\n",
    "params = list(rnn_encoder.parameters()) + list(rnn_decoder.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 0\n",
    "def train():\n",
    "    global steps\n",
    "    num_batches = 0\n",
    "    num_loss_prints = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(f\"Starting epoch {epoch} =====================\")\n",
    "\n",
    "        best_loss = 1e10\n",
    "        loss_sum = 0\n",
    "\n",
    "        for idx, sentences in enumerate(sentences_loader):\n",
    "\n",
    "            rnn_encoder.init_hidden_and_cell()\n",
    "\n",
    "\n",
    "            in_sentences = sentences['de_sentences']\n",
    "            in_lens = sentences['de_lens']\n",
    "            out_sentences = sentences['en_sentences']\n",
    "            out_lens = sentences['en_lens']\n",
    "\n",
    "\n",
    "            padded_in = pad_sequence(in_sentences, padding_value=0).to(device)\n",
    "            padded_out = pad_sequence(out_sentences, padding_value=0).to(device)\n",
    "\n",
    "            padded_in_one_hot = torch.zeros(padded_in.shape[0], padded_in.shape[1], dataset.get_de_dict_size()).to(device)\n",
    "            padded_in_one_hot = padded_in_one_hot.scatter_(2,padded_in.data,1)\n",
    "\n",
    "            rnn_encoder.forward((padded_in_one_hot, in_lens))\n",
    "            hidden, cell = rnn_encoder.get_hidden_and_cell()\n",
    "\n",
    "            rnn_decoder.init_hidden_and_cell(hidden,cell)\n",
    "\n",
    "            max_sentence_len = padded_out.shape[0]\n",
    "\n",
    "            y_pred = rnn_decoder.forward(dataset.get_en_eos_code(), dataset.get_en_dict_size(), max_sentence_len)\n",
    "\n",
    "            padded_out = padded_out[0:max_sentence_len]\n",
    "            padded_out_one_hot = torch.zeros(padded_out.shape[0], padded_out.shape[1], dataset.get_en_dict_size()).to(device)\n",
    "            padded_out_one_hot = padded_out_one_hot.scatter_(2,padded_out.data,1)\n",
    "\n",
    "            #Make all padded one-hot vectors to all zeros, which will make\n",
    "            #padded components loss 0 and so they wont affect the loss\n",
    "            padded_out_one_hot[:,:,0] = torch.zeros(max_sentence_len, padded_out_one_hot.shape[1])\n",
    "            loss = torch.sum(-torch.log(y_pred + 1e-9) * padded_out_one_hot)\n",
    "\n",
    "            loss_sum += loss.to('cpu').detach().data\n",
    "\n",
    "            #print(loss.to('cpu').detach().data)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Every 100 batches print the average loss and store the model weights\n",
    "            steps += BATCH_SIZE\n",
    "            num_batches += 1\n",
    "            loss_print_step = 200\n",
    "            if num_batches % loss_print_step == 0:\n",
    "\n",
    "                print(f\"{num_batches} Average loss in the last {loss_print_step} batches is {loss_sum/float(loss_print_step)}\")\n",
    "                steps = 0\n",
    "\n",
    "\n",
    "                num_loss_prints += 1 \n",
    "\n",
    "                if num_loss_prints % 10 == 0:\n",
    "                    print_results(in_sentences, out_sentences, y_pred.to('cpu').detach().data, num_batches)\n",
    "\n",
    "                if best_loss > loss_sum:\n",
    "                    best_loss = loss_sum\n",
    "\n",
    "                    models_path = \"models\"\n",
    "                    if not os.path.exists(models_path):\n",
    "                        os.mkdir(models_path)\n",
    "\n",
    "                    torch.save(rnn_encoder.state_dict(), trained_encoder_path)\n",
    "                    torch.save(rnn_decoder.state_dict(), trained_decoder_path)\n",
    "\n",
    "                loss_sum = 0\n",
    "                steps = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 =====================\n",
      "200 Average loss in the last 200 batches is 12456.51171875\n",
      "400 Average loss in the last 200 batches is 11314.78125\n",
      "600 Average loss in the last 200 batches is 11211.7890625\n",
      "800 Average loss in the last 200 batches is 11208.6103515625\n",
      "1000 Average loss in the last 200 batches is 11233.7509765625\n",
      "1200 Average loss in the last 200 batches is 11134.869140625\n",
      "1400 Average loss in the last 200 batches is 11068.5078125\n",
      "1600 Average loss in the last 200 batches is 11022.9384765625\n",
      "1800 Average loss in the last 200 batches is 10998.482421875\n",
      "2000 Average loss in the last 200 batches is 10920.26953125\n",
      "Printing sample predictions after 2000 batches in sentence_predictions.text\n",
      "2200 Average loss in the last 200 batches is 10852.3564453125\n",
      "2400 Average loss in the last 200 batches is 11001.01171875\n",
      "2600 Average loss in the last 200 batches is 10825.5224609375\n",
      "2800 Average loss in the last 200 batches is 10904.9560546875\n",
      "3000 Average loss in the last 200 batches is 10801.083984375\n",
      "3200 Average loss in the last 200 batches is 10797.236328125\n",
      "3400 Average loss in the last 200 batches is 10856.705078125\n",
      "3600 Average loss in the last 200 batches is 10895.798828125\n",
      "3800 Average loss in the last 200 batches is 10779.669921875\n",
      "4000 Average loss in the last 200 batches is 10873.4541015625\n",
      "Printing sample predictions after 4000 batches in sentence_predictions.text\n",
      "4200 Average loss in the last 200 batches is 10727.083984375\n",
      "4400 Average loss in the last 200 batches is 10731.865234375\n",
      "4600 Average loss in the last 200 batches is 10754.0654296875\n",
      "4800 Average loss in the last 200 batches is 10687.83984375\n",
      "5000 Average loss in the last 200 batches is 10660.5810546875\n",
      "5200 Average loss in the last 200 batches is 10627.5615234375\n",
      "5400 Average loss in the last 200 batches is 10688.0595703125\n",
      "5600 Average loss in the last 200 batches is 10694.400390625\n",
      "5800 Average loss in the last 200 batches is 10659.634765625\n",
      "6000 Average loss in the last 200 batches is 10500.8515625\n",
      "Printing sample predictions after 6000 batches in sentence_predictions.text\n",
      "6200 Average loss in the last 200 batches is 10493.888671875\n",
      "6400 Average loss in the last 200 batches is 10572.521484375\n",
      "6600 Average loss in the last 200 batches is 10564.9541015625\n",
      "6800 Average loss in the last 200 batches is 10604.7001953125\n",
      "7000 Average loss in the last 200 batches is 10529.4560546875\n",
      "7200 Average loss in the last 200 batches is 10418.482421875\n",
      "7400 Average loss in the last 200 batches is 10459.88671875\n",
      "7600 Average loss in the last 200 batches is 10411.7333984375\n",
      "7800 Average loss in the last 200 batches is 10457.1513671875\n",
      "8000 Average loss in the last 200 batches is 10457.1376953125\n",
      "Printing sample predictions after 8000 batches in sentence_predictions.text\n",
      "8200 Average loss in the last 200 batches is 10456.3046875\n",
      "8400 Average loss in the last 200 batches is 10492.1162109375\n",
      "8600 Average loss in the last 200 batches is 10396.8740234375\n",
      "8800 Average loss in the last 200 batches is 10401.021484375\n",
      "9000 Average loss in the last 200 batches is 10392.7705078125\n",
      "9200 Average loss in the last 200 batches is 10431.06640625\n",
      "9400 Average loss in the last 200 batches is 10294.130859375\n",
      "9600 Average loss in the last 200 batches is 10342.875\n",
      "9800 Average loss in the last 200 batches is 10327.814453125\n",
      "10000 Average loss in the last 200 batches is 10288.7900390625\n",
      "Printing sample predictions after 10000 batches in sentence_predictions.text\n",
      "10200 Average loss in the last 200 batches is 10296.0498046875\n",
      "10400 Average loss in the last 200 batches is 10267.5888671875\n",
      "10600 Average loss in the last 200 batches is 10310.41015625\n",
      "10800 Average loss in the last 200 batches is 10315.91796875\n",
      "11000 Average loss in the last 200 batches is 10314.34765625\n",
      "11200 Average loss in the last 200 batches is 10211.7216796875\n",
      "11400 Average loss in the last 200 batches is 10216.384765625\n",
      "11600 Average loss in the last 200 batches is 10205.79296875\n",
      "11800 Average loss in the last 200 batches is 10219.2265625\n",
      "12000 Average loss in the last 200 batches is 10285.0556640625\n",
      "Printing sample predictions after 12000 batches in sentence_predictions.text\n",
      "12200 Average loss in the last 200 batches is 10289.9697265625\n",
      "12400 Average loss in the last 200 batches is 10226.359375\n",
      "12600 Average loss in the last 200 batches is 10294.759765625\n",
      "12800 Average loss in the last 200 batches is 10184.1689453125\n",
      "13000 Average loss in the last 200 batches is 10122.7158203125\n",
      "13200 Average loss in the last 200 batches is 10153.5048828125\n",
      "13400 Average loss in the last 200 batches is 10106.1650390625\n",
      "13600 Average loss in the last 200 batches is 10047.3564453125\n",
      "13800 Average loss in the last 200 batches is 10101.1845703125\n",
      "14000 Average loss in the last 200 batches is 10202.685546875\n",
      "Printing sample predictions after 14000 batches in sentence_predictions.text\n",
      "14200 Average loss in the last 200 batches is 10050.59765625\n",
      "14400 Average loss in the last 200 batches is 10094.26953125\n",
      "14600 Average loss in the last 200 batches is 10109.65234375\n",
      "14800 Average loss in the last 200 batches is 10085.33203125\n",
      "15000 Average loss in the last 200 batches is 10093.16796875\n",
      "15200 Average loss in the last 200 batches is 10109.1572265625\n",
      "15400 Average loss in the last 200 batches is 10045.3359375\n",
      "15600 Average loss in the last 200 batches is 10068.3662109375\n",
      "15800 Average loss in the last 200 batches is 9937.8818359375\n",
      "16000 Average loss in the last 200 batches is 9963.365234375\n",
      "Printing sample predictions after 16000 batches in sentence_predictions.text\n",
      "16200 Average loss in the last 200 batches is 10019.2470703125\n",
      "16400 Average loss in the last 200 batches is 10012.5283203125\n",
      "16600 Average loss in the last 200 batches is 10047.5556640625\n",
      "16800 Average loss in the last 200 batches is 10034.68359375\n",
      "17000 Average loss in the last 200 batches is 9882.052734375\n",
      "17200 Average loss in the last 200 batches is 9903.5771484375\n",
      "17400 Average loss in the last 200 batches is 9946.0458984375\n",
      "17600 Average loss in the last 200 batches is 9941.849609375\n",
      "17800 Average loss in the last 200 batches is 9987.12890625\n",
      "18000 Average loss in the last 200 batches is 9950.3837890625\n",
      "Printing sample predictions after 18000 batches in sentence_predictions.text\n",
      "18200 Average loss in the last 200 batches is 9952.091796875\n",
      "18400 Average loss in the last 200 batches is 9956.3203125\n",
      "18600 Average loss in the last 200 batches is 10004.8642578125\n",
      "18800 Average loss in the last 200 batches is 9875.0029296875\n",
      "19000 Average loss in the last 200 batches is 9912.4052734375\n",
      "19200 Average loss in the last 200 batches is 9931.55078125\n",
      "19400 Average loss in the last 200 batches is 9902.669921875\n",
      "19600 Average loss in the last 200 batches is 9997.7509765625\n",
      "19800 Average loss in the last 200 batches is 9947.6318359375\n",
      "20000 Average loss in the last 200 batches is 9900.8330078125\n",
      "Printing sample predictions after 20000 batches in sentence_predictions.text\n",
      "20200 Average loss in the last 200 batches is 9860.3857421875\n",
      "20400 Average loss in the last 200 batches is 9899.3359375\n",
      "20600 Average loss in the last 200 batches is 9836.70703125\n",
      "20800 Average loss in the last 200 batches is 9791.6904296875\n",
      "21000 Average loss in the last 200 batches is 9828.423828125\n",
      "21200 Average loss in the last 200 batches is 9760.8759765625\n",
      "21400 Average loss in the last 200 batches is 9795.6748046875\n",
      "21600 Average loss in the last 200 batches is 9761.10546875\n",
      "21800 Average loss in the last 200 batches is 9795.25\n",
      "22000 Average loss in the last 200 batches is 9759.234375\n",
      "Printing sample predictions after 22000 batches in sentence_predictions.text\n",
      "22200 Average loss in the last 200 batches is 9818.740234375\n",
      "22400 Average loss in the last 200 batches is 9719.197265625\n",
      "22600 Average loss in the last 200 batches is 9765.0537109375\n",
      "22800 Average loss in the last 200 batches is 9771.328125\n",
      "23000 Average loss in the last 200 batches is 9777.2919921875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-583acb19969b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrnn_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_and_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-55300b1c88f5>\u001b[0m in \u001b[0;36minit_hidden_and_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden_and_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN_HIDDEN_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRNN_HIDDEN_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 =====================\n",
      "200 Average loss in the last 200 batches is 9747.49609375\n",
      "400 Average loss in the last 200 batches is 9838.896484375\n",
      "600 Average loss in the last 200 batches is 9838.03125\n",
      "800 Average loss in the last 200 batches is 9887.501953125\n",
      "1000 Average loss in the last 200 batches is 9797.1171875\n",
      "1200 Average loss in the last 200 batches is 9779.291015625\n",
      "1400 Average loss in the last 200 batches is 9824.8076171875\n",
      "1600 Average loss in the last 200 batches is 9809.30078125\n",
      "1800 Average loss in the last 200 batches is 9745.7041015625\n",
      "2000 Average loss in the last 200 batches is 9747.541015625\n",
      "Printing sample predictions after 2000 batches in sentence_predictions.text\n",
      "2200 Average loss in the last 200 batches is 9720.42578125\n",
      "2400 Average loss in the last 200 batches is 9672.2802734375\n",
      "2600 Average loss in the last 200 batches is 9758.294921875\n",
      "2800 Average loss in the last 200 batches is 9755.1083984375\n",
      "3000 Average loss in the last 200 batches is 9773.0859375\n",
      "3200 Average loss in the last 200 batches is 9656.0634765625\n",
      "3400 Average loss in the last 200 batches is 9736.400390625\n",
      "3600 Average loss in the last 200 batches is 9695.998046875\n",
      "3800 Average loss in the last 200 batches is 9642.06640625\n",
      "4000 Average loss in the last 200 batches is 9689.576171875\n",
      "Printing sample predictions after 4000 batches in sentence_predictions.text\n",
      "4200 Average loss in the last 200 batches is 9830.1533203125\n",
      "4400 Average loss in the last 200 batches is 9669.0546875\n",
      "4600 Average loss in the last 200 batches is 9625.146484375\n",
      "4800 Average loss in the last 200 batches is 9706.12890625\n",
      "5000 Average loss in the last 200 batches is 9733.5498046875\n",
      "5200 Average loss in the last 200 batches is 9712.2861328125\n",
      "5400 Average loss in the last 200 batches is 9649.1845703125\n",
      "5600 Average loss in the last 200 batches is 9722.5439453125\n",
      "5800 Average loss in the last 200 batches is 9680.8916015625\n",
      "6000 Average loss in the last 200 batches is 9596.8154296875\n",
      "Printing sample predictions after 6000 batches in sentence_predictions.text\n",
      "6200 Average loss in the last 200 batches is 9645.744140625\n",
      "6400 Average loss in the last 200 batches is 9529.73828125\n",
      "6600 Average loss in the last 200 batches is 9494.2734375\n",
      "6800 Average loss in the last 200 batches is 9643.958984375\n",
      "7000 Average loss in the last 200 batches is 9597.2880859375\n",
      "7200 Average loss in the last 200 batches is 9596.18359375\n",
      "7400 Average loss in the last 200 batches is 9484.5439453125\n",
      "7600 Average loss in the last 200 batches is 9515.91015625\n",
      "7800 Average loss in the last 200 batches is 9630.7919921875\n",
      "8000 Average loss in the last 200 batches is 9536.8837890625\n",
      "Printing sample predictions after 8000 batches in sentence_predictions.text\n",
      "8200 Average loss in the last 200 batches is 9492.7822265625\n",
      "8400 Average loss in the last 200 batches is 9497.78515625\n",
      "8600 Average loss in the last 200 batches is 9510.4501953125\n",
      "8800 Average loss in the last 200 batches is 9530.5703125\n",
      "9000 Average loss in the last 200 batches is 9554.2998046875\n",
      "9200 Average loss in the last 200 batches is 9514.73046875\n",
      "9400 Average loss in the last 200 batches is 9470.3916015625\n",
      "9600 Average loss in the last 200 batches is 9433.478515625\n",
      "9800 Average loss in the last 200 batches is 9536.3896484375\n",
      "10000 Average loss in the last 200 batches is 9511.3017578125\n",
      "Printing sample predictions after 10000 batches in sentence_predictions.text\n",
      "10200 Average loss in the last 200 batches is 9407.302734375\n",
      "10400 Average loss in the last 200 batches is 9522.08984375\n",
      "10600 Average loss in the last 200 batches is 9513.4150390625\n",
      "10800 Average loss in the last 200 batches is 9439.1806640625\n",
      "11000 Average loss in the last 200 batches is 9513.9111328125\n",
      "11200 Average loss in the last 200 batches is 9469.0693359375\n",
      "11400 Average loss in the last 200 batches is 9448.9501953125\n",
      "11600 Average loss in the last 200 batches is 9352.8291015625\n",
      "11800 Average loss in the last 200 batches is 9329.65625\n",
      "12000 Average loss in the last 200 batches is 9386.005859375\n",
      "Printing sample predictions after 12000 batches in sentence_predictions.text\n",
      "12200 Average loss in the last 200 batches is 9365.1494140625\n",
      "12400 Average loss in the last 200 batches is 9395.8896484375\n",
      "12600 Average loss in the last 200 batches is 9422.3701171875\n",
      "12800 Average loss in the last 200 batches is 9402.8857421875\n",
      "13000 Average loss in the last 200 batches is 9387.12109375\n",
      "13200 Average loss in the last 200 batches is 9364.630859375\n",
      "13400 Average loss in the last 200 batches is 9356.7041015625\n",
      "13600 Average loss in the last 200 batches is 9438.88671875\n",
      "13800 Average loss in the last 200 batches is 9372.7822265625\n",
      "14000 Average loss in the last 200 batches is 9372.9619140625\n",
      "Printing sample predictions after 14000 batches in sentence_predictions.text\n",
      "14200 Average loss in the last 200 batches is 9297.9833984375\n",
      "14400 Average loss in the last 200 batches is 9388.998046875\n",
      "14600 Average loss in the last 200 batches is 9409.1328125\n",
      "14800 Average loss in the last 200 batches is 9350.4462890625\n",
      "15000 Average loss in the last 200 batches is 9348.681640625\n",
      "15200 Average loss in the last 200 batches is 9287.6650390625\n",
      "15400 Average loss in the last 200 batches is 9292.7626953125\n",
      "15600 Average loss in the last 200 batches is 9245.3056640625\n",
      "15800 Average loss in the last 200 batches is 9281.8779296875\n",
      "16000 Average loss in the last 200 batches is 9292.263671875\n",
      "Printing sample predictions after 16000 batches in sentence_predictions.text\n",
      "16200 Average loss in the last 200 batches is 9360.7734375\n",
      "16400 Average loss in the last 200 batches is 9277.9814453125\n",
      "16600 Average loss in the last 200 batches is 9441.265625\n",
      "16800 Average loss in the last 200 batches is 9298.306640625\n",
      "17000 Average loss in the last 200 batches is 9261.8232421875\n",
      "17200 Average loss in the last 200 batches is 9268.8251953125\n",
      "17400 Average loss in the last 200 batches is 9244.1904296875\n",
      "17600 Average loss in the last 200 batches is 9258.7197265625\n",
      "17800 Average loss in the last 200 batches is 9295.505859375\n",
      "18000 Average loss in the last 200 batches is 9263.181640625\n",
      "Printing sample predictions after 18000 batches in sentence_predictions.text\n",
      "18200 Average loss in the last 200 batches is 9234.66796875\n",
      "18400 Average loss in the last 200 batches is 9189.376953125\n",
      "18600 Average loss in the last 200 batches is 9212.681640625\n",
      "18800 Average loss in the last 200 batches is 9196.3837890625\n",
      "19000 Average loss in the last 200 batches is 9219.416015625\n",
      "19200 Average loss in the last 200 batches is 9243.47265625\n",
      "19400 Average loss in the last 200 batches is 9214.0302734375\n",
      "19600 Average loss in the last 200 batches is 9236.2529296875\n",
      "19800 Average loss in the last 200 batches is 9291.7763671875\n",
      "20000 Average loss in the last 200 batches is 9144.6640625\n",
      "Printing sample predictions after 20000 batches in sentence_predictions.text\n",
      "20200 Average loss in the last 200 batches is 9226.05078125\n",
      "20400 Average loss in the last 200 batches is 9120.8759765625\n",
      "20600 Average loss in the last 200 batches is 9096.1982421875\n",
      "20800 Average loss in the last 200 batches is 9215.3603515625\n",
      "21000 Average loss in the last 200 batches is 9217.615234375\n",
      "21200 Average loss in the last 200 batches is 9135.9873046875\n",
      "21400 Average loss in the last 200 batches is 9159.1396484375\n",
      "21600 Average loss in the last 200 batches is 9184.48828125\n",
      "21800 Average loss in the last 200 batches is 9192.50390625\n",
      "22000 Average loss in the last 200 batches is 9158.44140625\n",
      "Printing sample predictions after 22000 batches in sentence_predictions.text\n",
      "22200 Average loss in the last 200 batches is 9213.501953125\n",
      "22400 Average loss in the last 200 batches is 9097.443359375\n",
      "22600 Average loss in the last 200 batches is 9130.046875\n",
      "22800 Average loss in the last 200 batches is 9171.2802734375\n",
      "23000 Average loss in the last 200 batches is 9152.486328125\n",
      "23200 Average loss in the last 200 batches is 9060.12109375\n",
      "23400 Average loss in the last 200 batches is 9070.06640625\n",
      "23600 Average loss in the last 200 batches is 9037.7119140625\n",
      "23800 Average loss in the last 200 batches is 9092.8720703125\n",
      "24000 Average loss in the last 200 batches is 9121.783203125\n",
      "Printing sample predictions after 24000 batches in sentence_predictions.text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24200 Average loss in the last 200 batches is 9097.5791015625\n",
      "24400 Average loss in the last 200 batches is 9155.7392578125\n",
      "24600 Average loss in the last 200 batches is 9137.91796875\n",
      "24800 Average loss in the last 200 batches is 9061.6142578125\n",
      "25000 Average loss in the last 200 batches is 9092.25\n",
      "25200 Average loss in the last 200 batches is 9058.88671875\n",
      "25400 Average loss in the last 200 batches is 9061.0341796875\n",
      "25600 Average loss in the last 200 batches is 9101.041015625\n",
      "25800 Average loss in the last 200 batches is 9056.2060546875\n",
      "26000 Average loss in the last 200 batches is 8972.74609375\n",
      "Printing sample predictions after 26000 batches in sentence_predictions.text\n",
      "26200 Average loss in the last 200 batches is 9111.7197265625\n",
      "26400 Average loss in the last 200 batches is 9089.14453125\n",
      "26600 Average loss in the last 200 batches is 9092.103515625\n",
      "26800 Average loss in the last 200 batches is 8986.541015625\n",
      "27000 Average loss in the last 200 batches is 9046.9296875\n",
      "27200 Average loss in the last 200 batches is 8977.0166015625\n",
      "27400 Average loss in the last 200 batches is 9037.6416015625\n",
      "27600 Average loss in the last 200 batches is 9080.12109375\n",
      "27800 Average loss in the last 200 batches is 9039.9873046875\n",
      "28000 Average loss in the last 200 batches is 9107.53515625\n",
      "Printing sample predictions after 28000 batches in sentence_predictions.text\n",
      "28200 Average loss in the last 200 batches is 8992.234375\n",
      "28400 Average loss in the last 200 batches is 9006.96875\n",
      "28600 Average loss in the last 200 batches is 8947.1591796875\n",
      "28800 Average loss in the last 200 batches is 9114.705078125\n",
      "29000 Average loss in the last 200 batches is 9115.9765625\n",
      "29200 Average loss in the last 200 batches is 9041.181640625\n",
      "29400 Average loss in the last 200 batches is 8914.1953125\n",
      "29600 Average loss in the last 200 batches is 9030.51953125\n",
      "29800 Average loss in the last 200 batches is 9035.6220703125\n",
      "30000 Average loss in the last 200 batches is 8982.2314453125\n",
      "Printing sample predictions after 30000 batches in sentence_predictions.text\n",
      "30200 Average loss in the last 200 batches is 9021.1376953125\n",
      "30400 Average loss in the last 200 batches is 8977.1953125\n",
      "30600 Average loss in the last 200 batches is 8916.87109375\n",
      "30800 Average loss in the last 200 batches is 9056.5390625\n",
      "31000 Average loss in the last 200 batches is 8927.0224609375\n",
      "31200 Average loss in the last 200 batches is 8896.0126953125\n",
      "31400 Average loss in the last 200 batches is 8944.6552734375\n",
      "31600 Average loss in the last 200 batches is 8956.1787109375\n",
      "31800 Average loss in the last 200 batches is 8897.82421875\n",
      "32000 Average loss in the last 200 batches is 8964.9970703125\n",
      "Printing sample predictions after 32000 batches in sentence_predictions.text\n",
      "32200 Average loss in the last 200 batches is 8947.3759765625\n",
      "32400 Average loss in the last 200 batches is 8931.25\n",
      "32600 Average loss in the last 200 batches is 8932.927734375\n",
      "32800 Average loss in the last 200 batches is 8922.037109375\n",
      "33000 Average loss in the last 200 batches is 8904.5498046875\n",
      "33200 Average loss in the last 200 batches is 8960.6552734375\n",
      "33400 Average loss in the last 200 batches is 8934.22265625\n",
      "33600 Average loss in the last 200 batches is 8944.7978515625\n",
      "33800 Average loss in the last 200 batches is 8875.6474609375\n",
      "34000 Average loss in the last 200 batches is 8909.1376953125\n",
      "Printing sample predictions after 34000 batches in sentence_predictions.text\n",
      "34200 Average loss in the last 200 batches is 8876.7587890625\n",
      "34400 Average loss in the last 200 batches is 8857.5166015625\n",
      "34600 Average loss in the last 200 batches is 8890.671875\n",
      "34800 Average loss in the last 200 batches is 8942.18359375\n",
      "35000 Average loss in the last 200 batches is 8915.5654296875\n",
      "35200 Average loss in the last 200 batches is 8972.6533203125\n",
      "35400 Average loss in the last 200 batches is 8926.4365234375\n",
      "35600 Average loss in the last 200 batches is 8859.3759765625\n",
      "35800 Average loss in the last 200 batches is 8893.5029296875\n",
      "36000 Average loss in the last 200 batches is 8927.0810546875\n",
      "Printing sample predictions after 36000 batches in sentence_predictions.text\n",
      "36200 Average loss in the last 200 batches is 8915.3125\n",
      "36400 Average loss in the last 200 batches is 8885.8837890625\n",
      "36600 Average loss in the last 200 batches is 8915.166015625\n",
      "36800 Average loss in the last 200 batches is 8877.765625\n",
      "37000 Average loss in the last 200 batches is 8826.3779296875\n",
      "37200 Average loss in the last 200 batches is 8806.9248046875\n",
      "37400 Average loss in the last 200 batches is 8947.4130859375\n",
      "37600 Average loss in the last 200 batches is 8792.5146484375\n",
      "37800 Average loss in the last 200 batches is 8929.0634765625\n",
      "38000 Average loss in the last 200 batches is 8791.1162109375\n",
      "Printing sample predictions after 38000 batches in sentence_predictions.text\n",
      "38200 Average loss in the last 200 batches is 8851.658203125\n",
      "38400 Average loss in the last 200 batches is 8848.650390625\n",
      "38600 Average loss in the last 200 batches is 8780.4287109375\n",
      "38800 Average loss in the last 200 batches is 8837.4052734375\n",
      "39000 Average loss in the last 200 batches is 8864.041015625\n",
      "39200 Average loss in the last 200 batches is 8811.5078125\n",
      "39400 Average loss in the last 200 batches is 8925.6865234375\n",
      "39600 Average loss in the last 200 batches is 8752.1708984375\n",
      "39800 Average loss in the last 200 batches is 8837.7021484375\n",
      "40000 Average loss in the last 200 batches is 8867.58984375\n",
      "Printing sample predictions after 40000 batches in sentence_predictions.text\n",
      "40200 Average loss in the last 200 batches is 8792.017578125\n",
      "40400 Average loss in the last 200 batches is 8812.91015625\n",
      "40600 Average loss in the last 200 batches is 8763.5947265625\n",
      "40800 Average loss in the last 200 batches is 8808.6376953125\n",
      "41000 Average loss in the last 200 batches is 8767.1572265625\n",
      "41200 Average loss in the last 200 batches is 8800.6083984375\n",
      "41400 Average loss in the last 200 batches is 8831.376953125\n",
      "41600 Average loss in the last 200 batches is 8753.5517578125\n",
      "41800 Average loss in the last 200 batches is 8742.4296875\n",
      "42000 Average loss in the last 200 batches is 8719.55078125\n",
      "Printing sample predictions after 42000 batches in sentence_predictions.text\n",
      "42200 Average loss in the last 200 batches is 8881.2626953125\n",
      "42400 Average loss in the last 200 batches is 8813.630859375\n",
      "42600 Average loss in the last 200 batches is 8766.072265625\n",
      "42800 Average loss in the last 200 batches is 8849.755859375\n",
      "43000 Average loss in the last 200 batches is 8871.1806640625\n",
      "43200 Average loss in the last 200 batches is 8792.783203125\n",
      "43400 Average loss in the last 200 batches is 8684.853515625\n",
      "43600 Average loss in the last 200 batches is 8770.0400390625\n",
      "43800 Average loss in the last 200 batches is 8804.9013671875\n",
      "44000 Average loss in the last 200 batches is 8821.318359375\n",
      "Printing sample predictions after 44000 batches in sentence_predictions.text\n",
      "44200 Average loss in the last 200 batches is 8729.072265625\n",
      "44400 Average loss in the last 200 batches is 8711.0966796875\n",
      "44600 Average loss in the last 200 batches is 8752.08203125\n",
      "44800 Average loss in the last 200 batches is 8680.01171875\n",
      "45000 Average loss in the last 200 batches is 8749.853515625\n",
      "45200 Average loss in the last 200 batches is 8772.7939453125\n",
      "45400 Average loss in the last 200 batches is 8721.70703125\n",
      "45600 Average loss in the last 200 batches is 8675.3876953125\n",
      "45800 Average loss in the last 200 batches is 8707.03515625\n",
      "46000 Average loss in the last 200 batches is 8756.4736328125\n",
      "Printing sample predictions after 46000 batches in sentence_predictions.text\n",
      "46200 Average loss in the last 200 batches is 8744.3046875\n",
      "46400 Average loss in the last 200 batches is 8653.2529296875\n",
      "46600 Average loss in the last 200 batches is 8730.49609375\n",
      "46800 Average loss in the last 200 batches is 8730.3583984375\n",
      "47000 Average loss in the last 200 batches is 8679.6015625\n",
      "47200 Average loss in the last 200 batches is 8718.234375\n",
      "47400 Average loss in the last 200 batches is 8716.056640625\n",
      "47600 Average loss in the last 200 batches is 8777.6669921875\n",
      "47800 Average loss in the last 200 batches is 8717.03125\n",
      "48000 Average loss in the last 200 batches is 8715.4951171875\n",
      "Printing sample predictions after 48000 batches in sentence_predictions.text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48200 Average loss in the last 200 batches is 8701.6298828125\n",
      "48400 Average loss in the last 200 batches is 8666.4658203125\n",
      "48600 Average loss in the last 200 batches is 8714.48046875\n",
      "48800 Average loss in the last 200 batches is 8730.14453125\n",
      "49000 Average loss in the last 200 batches is 8733.6025390625\n",
      "49200 Average loss in the last 200 batches is 8700.58984375\n",
      "49400 Average loss in the last 200 batches is 8624.59375\n",
      "49600 Average loss in the last 200 batches is 8746.4130859375\n",
      "49800 Average loss in the last 200 batches is 8703.1240234375\n",
      "50000 Average loss in the last 200 batches is 8704.4404296875\n",
      "Printing sample predictions after 50000 batches in sentence_predictions.text\n",
      "50200 Average loss in the last 200 batches is 8705.70703125\n",
      "50400 Average loss in the last 200 batches is 8644.94140625\n",
      "50600 Average loss in the last 200 batches is 8657.5615234375\n",
      "50800 Average loss in the last 200 batches is 8682.419921875\n",
      "51000 Average loss in the last 200 batches is 8618.341796875\n",
      "51200 Average loss in the last 200 batches is 8670.8935546875\n",
      "51400 Average loss in the last 200 batches is 8643.37890625\n",
      "51600 Average loss in the last 200 batches is 8668.8330078125\n",
      "51800 Average loss in the last 200 batches is 8711.6572265625\n",
      "52000 Average loss in the last 200 batches is 8627.296875\n",
      "Printing sample predictions after 52000 batches in sentence_predictions.text\n",
      "52200 Average loss in the last 200 batches is 8645.443359375\n",
      "52400 Average loss in the last 200 batches is 8556.48046875\n",
      "52600 Average loss in the last 200 batches is 8686.3408203125\n",
      "52800 Average loss in the last 200 batches is 8701.7158203125\n",
      "53000 Average loss in the last 200 batches is 8701.1435546875\n",
      "53200 Average loss in the last 200 batches is 8649.1435546875\n",
      "53400 Average loss in the last 200 batches is 8574.787109375\n",
      "53600 Average loss in the last 200 batches is 8606.572265625\n",
      "53800 Average loss in the last 200 batches is 8733.107421875\n",
      "54000 Average loss in the last 200 batches is 8599.349609375\n",
      "Printing sample predictions after 54000 batches in sentence_predictions.text\n",
      "54200 Average loss in the last 200 batches is 8627.4970703125\n",
      "54400 Average loss in the last 200 batches is 8669.001953125\n",
      "54600 Average loss in the last 200 batches is 8590.8896484375\n",
      "54800 Average loss in the last 200 batches is 8652.9951171875\n",
      "55000 Average loss in the last 200 batches is 8659.8798828125\n",
      "55200 Average loss in the last 200 batches is 8650.7236328125\n",
      "55400 Average loss in the last 200 batches is 8613.9501953125\n",
      "55600 Average loss in the last 200 batches is 8597.974609375\n",
      "55800 Average loss in the last 200 batches is 8666.5810546875\n",
      "56000 Average loss in the last 200 batches is 8538.40234375\n",
      "Printing sample predictions after 56000 batches in sentence_predictions.text\n",
      "56200 Average loss in the last 200 batches is 8769.9384765625\n",
      "56400 Average loss in the last 200 batches is 8568.1484375\n",
      "56600 Average loss in the last 200 batches is 8597.296875\n",
      "56800 Average loss in the last 200 batches is 8656.0166015625\n",
      "57000 Average loss in the last 200 batches is 8657.9462890625\n",
      "57200 Average loss in the last 200 batches is 8581.56640625\n",
      "57400 Average loss in the last 200 batches is 8558.2373046875\n",
      "57600 Average loss in the last 200 batches is 8536.56640625\n",
      "57800 Average loss in the last 200 batches is 8590.3095703125\n",
      "58000 Average loss in the last 200 batches is 8589.3876953125\n",
      "Printing sample predictions after 58000 batches in sentence_predictions.text\n",
      "58200 Average loss in the last 200 batches is 8639.3330078125\n",
      "58400 Average loss in the last 200 batches is 8645.0390625\n",
      "58600 Average loss in the last 200 batches is 8620.3046875\n",
      "58800 Average loss in the last 200 batches is 8591.796875\n",
      "59000 Average loss in the last 200 batches is 8574.5341796875\n",
      "59200 Average loss in the last 200 batches is 8580.4345703125\n",
      "59400 Average loss in the last 200 batches is 8606.9736328125\n",
      "59600 Average loss in the last 200 batches is 8553.3310546875\n",
      "59800 Average loss in the last 200 batches is 8621.7509765625\n",
      "60000 Average loss in the last 200 batches is 8576.65625\n",
      "Printing sample predictions after 60000 batches in sentence_predictions.text\n",
      "60200 Average loss in the last 200 batches is 8495.0966796875\n",
      "60400 Average loss in the last 200 batches is 8540.4677734375\n",
      "60600 Average loss in the last 200 batches is 8668.7626953125\n",
      "60800 Average loss in the last 200 batches is 8585.41015625\n",
      "61000 Average loss in the last 200 batches is 8574.4482421875\n",
      "61200 Average loss in the last 200 batches is 8551.0693359375\n",
      "61400 Average loss in the last 200 batches is 8490.9228515625\n",
      "61600 Average loss in the last 200 batches is 8567.7255859375\n",
      "61800 Average loss in the last 200 batches is 8475.06640625\n",
      "62000 Average loss in the last 200 batches is 8490.3037109375\n",
      "Printing sample predictions after 62000 batches in sentence_predictions.text\n",
      "62200 Average loss in the last 200 batches is 8517.349609375\n",
      "62400 Average loss in the last 200 batches is 8562.3701171875\n",
      "62600 Average loss in the last 200 batches is 8583.8720703125\n",
      "62800 Average loss in the last 200 batches is 8527.1845703125\n",
      "63000 Average loss in the last 200 batches is 8557.4814453125\n",
      "63200 Average loss in the last 200 batches is 8546.251953125\n",
      "63400 Average loss in the last 200 batches is 8505.669921875\n",
      "63600 Average loss in the last 200 batches is 8460.150390625\n",
      "63800 Average loss in the last 200 batches is 8474.806640625\n",
      "64000 Average loss in the last 200 batches is 8592.1044921875\n",
      "Printing sample predictions after 64000 batches in sentence_predictions.text\n",
      "64200 Average loss in the last 200 batches is 8517.6708984375\n",
      "64400 Average loss in the last 200 batches is 8514.5126953125\n",
      "64600 Average loss in the last 200 batches is 8515.7646484375\n",
      "64800 Average loss in the last 200 batches is 8505.7548828125\n",
      "65000 Average loss in the last 200 batches is 8563.837890625\n",
      "65200 Average loss in the last 200 batches is 8524.29296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0ddb2554a7f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpadded_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mpadded_in_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_de_dict_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mpadded_in_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_in_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadded_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 =====================\n",
      "200 Average loss in the last 200 batches is 8515.95703125\n",
      "400 Average loss in the last 200 batches is 8485.75\n",
      "600 Average loss in the last 200 batches is 8553.5283203125\n",
      "800 Average loss in the last 200 batches is 8567.0166015625\n",
      "1000 Average loss in the last 200 batches is 8530.3193359375\n",
      "1200 Average loss in the last 200 batches is 8580.306640625\n",
      "1400 Average loss in the last 200 batches is 8576.2333984375\n",
      "1600 Average loss in the last 200 batches is 8550.1787109375\n",
      "1800 Average loss in the last 200 batches is 8647.04296875\n",
      "2000 Average loss in the last 200 batches is 8578.50390625\n",
      "Printing sample predictions after 2000 batches in sentence_predictions.text\n",
      "2200 Average loss in the last 200 batches is 8517.2197265625\n",
      "2400 Average loss in the last 200 batches is 8599.896484375\n",
      "2600 Average loss in the last 200 batches is 8481.1123046875\n",
      "2800 Average loss in the last 200 batches is 8500.046875\n",
      "3000 Average loss in the last 200 batches is 8501.99609375\n",
      "3200 Average loss in the last 200 batches is 8504.62109375\n",
      "3400 Average loss in the last 200 batches is 8501.1591796875\n",
      "3600 Average loss in the last 200 batches is 8468.8740234375\n",
      "3800 Average loss in the last 200 batches is 8585.271484375\n",
      "4000 Average loss in the last 200 batches is 8468.974609375\n",
      "Printing sample predictions after 4000 batches in sentence_predictions.text\n",
      "4200 Average loss in the last 200 batches is 8437.81640625\n",
      "4400 Average loss in the last 200 batches is 8588.51171875\n",
      "4600 Average loss in the last 200 batches is 8518.8095703125\n",
      "4800 Average loss in the last 200 batches is 8528.1953125\n",
      "5000 Average loss in the last 200 batches is 8525.810546875\n",
      "5200 Average loss in the last 200 batches is 8511.4462890625\n",
      "5400 Average loss in the last 200 batches is 8472.01171875\n",
      "5600 Average loss in the last 200 batches is 8431.7001953125\n",
      "5800 Average loss in the last 200 batches is 8445.791015625\n",
      "6000 Average loss in the last 200 batches is 8452.5859375\n",
      "Printing sample predictions after 6000 batches in sentence_predictions.text\n",
      "6200 Average loss in the last 200 batches is 8444.5634765625\n",
      "6400 Average loss in the last 200 batches is 8435.44921875\n",
      "6600 Average loss in the last 200 batches is 8422.509765625\n",
      "6800 Average loss in the last 200 batches is 8446.5908203125\n",
      "7000 Average loss in the last 200 batches is 8480.787109375\n",
      "7200 Average loss in the last 200 batches is 8472.984375\n",
      "7400 Average loss in the last 200 batches is 8381.8935546875\n",
      "7600 Average loss in the last 200 batches is 8427.3154296875\n",
      "7800 Average loss in the last 200 batches is 8488.3896484375\n",
      "8000 Average loss in the last 200 batches is 8438.7490234375\n",
      "Printing sample predictions after 8000 batches in sentence_predictions.text\n",
      "8200 Average loss in the last 200 batches is 8492.4951171875\n",
      "8400 Average loss in the last 200 batches is 8492.291015625\n",
      "8600 Average loss in the last 200 batches is 8488.1845703125\n",
      "8800 Average loss in the last 200 batches is 8468.447265625\n",
      "9000 Average loss in the last 200 batches is 8487.611328125\n",
      "9200 Average loss in the last 200 batches is 8402.6259765625\n",
      "9400 Average loss in the last 200 batches is 8470.18359375\n",
      "9600 Average loss in the last 200 batches is 8408.087890625\n",
      "9800 Average loss in the last 200 batches is 8399.0498046875\n",
      "10000 Average loss in the last 200 batches is 8421.638671875\n",
      "Printing sample predictions after 10000 batches in sentence_predictions.text\n",
      "10200 Average loss in the last 200 batches is 8545.5126953125\n",
      "10400 Average loss in the last 200 batches is 8445.25\n",
      "10600 Average loss in the last 200 batches is 8443.4697265625\n",
      "10800 Average loss in the last 200 batches is 8454.263671875\n",
      "11000 Average loss in the last 200 batches is 8463.958984375\n",
      "11200 Average loss in the last 200 batches is 8408.6279296875\n",
      "11400 Average loss in the last 200 batches is 8401.5537109375\n",
      "11600 Average loss in the last 200 batches is 8377.7841796875\n",
      "11800 Average loss in the last 200 batches is 8399.1279296875\n",
      "12000 Average loss in the last 200 batches is 8450.8623046875\n",
      "Printing sample predictions after 12000 batches in sentence_predictions.text\n",
      "12200 Average loss in the last 200 batches is 8403.8251953125\n",
      "12400 Average loss in the last 200 batches is 8418.1005859375\n",
      "12600 Average loss in the last 200 batches is 8376.7470703125\n",
      "12800 Average loss in the last 200 batches is 8372.6416015625\n",
      "13000 Average loss in the last 200 batches is 8421.1748046875\n",
      "13200 Average loss in the last 200 batches is 8485.173828125\n",
      "13400 Average loss in the last 200 batches is 8416.7529296875\n",
      "13600 Average loss in the last 200 batches is 8385.71484375\n",
      "13800 Average loss in the last 200 batches is 8459.5390625\n",
      "14000 Average loss in the last 200 batches is 8402.77734375\n",
      "Printing sample predictions after 14000 batches in sentence_predictions.text\n",
      "14200 Average loss in the last 200 batches is 8450.306640625\n",
      "14400 Average loss in the last 200 batches is 8449.212890625\n",
      "14600 Average loss in the last 200 batches is 8351.267578125\n",
      "14800 Average loss in the last 200 batches is 8411.701171875\n",
      "15000 Average loss in the last 200 batches is 8351.6015625\n",
      "15200 Average loss in the last 200 batches is 8390.68359375\n",
      "15400 Average loss in the last 200 batches is 8403.82421875\n",
      "15600 Average loss in the last 200 batches is 8405.447265625\n",
      "15800 Average loss in the last 200 batches is 8327.1640625\n",
      "16000 Average loss in the last 200 batches is 8375.603515625\n",
      "Printing sample predictions after 16000 batches in sentence_predictions.text\n",
      "16200 Average loss in the last 200 batches is 8473.8330078125\n",
      "16400 Average loss in the last 200 batches is 8418.115234375\n",
      "16600 Average loss in the last 200 batches is 8390.390625\n",
      "16800 Average loss in the last 200 batches is 8328.958984375\n",
      "17000 Average loss in the last 200 batches is 8390.6103515625\n",
      "17200 Average loss in the last 200 batches is 8411.0029296875\n",
      "17400 Average loss in the last 200 batches is 8313.8173828125\n",
      "17600 Average loss in the last 200 batches is 8372.3095703125\n",
      "17800 Average loss in the last 200 batches is 8394.041015625\n",
      "18000 Average loss in the last 200 batches is 8350.775390625\n",
      "Printing sample predictions after 18000 batches in sentence_predictions.text\n",
      "18200 Average loss in the last 200 batches is 8379.8583984375\n",
      "18400 Average loss in the last 200 batches is 8279.01953125\n",
      "18600 Average loss in the last 200 batches is 8304.083984375\n",
      "18800 Average loss in the last 200 batches is 8262.6376953125\n",
      "19000 Average loss in the last 200 batches is 8333.0107421875\n",
      "19200 Average loss in the last 200 batches is 8351.958984375\n",
      "19400 Average loss in the last 200 batches is 8376.1396484375\n",
      "19600 Average loss in the last 200 batches is 8321.5322265625\n",
      "19800 Average loss in the last 200 batches is 8296.681640625\n",
      "20000 Average loss in the last 200 batches is 8303.6611328125\n",
      "Printing sample predictions after 20000 batches in sentence_predictions.text\n",
      "20200 Average loss in the last 200 batches is 8332.86328125\n",
      "20400 Average loss in the last 200 batches is 8425.02734375\n",
      "20600 Average loss in the last 200 batches is 8388.5634765625\n",
      "20800 Average loss in the last 200 batches is 8334.5439453125\n",
      "21000 Average loss in the last 200 batches is 8352.79296875\n",
      "21200 Average loss in the last 200 batches is 8269.9296875\n",
      "21400 Average loss in the last 200 batches is 8269.27734375\n",
      "21600 Average loss in the last 200 batches is 8318.4716796875\n",
      "21800 Average loss in the last 200 batches is 8348.6416015625\n",
      "22000 Average loss in the last 200 batches is 8304.7333984375\n",
      "Printing sample predictions after 22000 batches in sentence_predictions.text\n",
      "22200 Average loss in the last 200 batches is 8351.9990234375\n",
      "22400 Average loss in the last 200 batches is 8345.39453125\n",
      "22600 Average loss in the last 200 batches is 8308.818359375\n",
      "22800 Average loss in the last 200 batches is 8385.1064453125\n",
      "23000 Average loss in the last 200 batches is 8439.75\n",
      "23200 Average loss in the last 200 batches is 8344.5576171875\n",
      "23400 Average loss in the last 200 batches is 8363.2470703125\n",
      "23600 Average loss in the last 200 batches is 8375.13671875\n",
      "23800 Average loss in the last 200 batches is 8432.2978515625\n",
      "24000 Average loss in the last 200 batches is 8320.9228515625\n",
      "Printing sample predictions after 24000 batches in sentence_predictions.text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24200 Average loss in the last 200 batches is 8355.32421875\n",
      "24400 Average loss in the last 200 batches is 8219.5791015625\n",
      "24600 Average loss in the last 200 batches is 8335.9970703125\n",
      "24800 Average loss in the last 200 batches is 8272.494140625\n",
      "25000 Average loss in the last 200 batches is 8427.666015625\n",
      "25200 Average loss in the last 200 batches is 8368.103515625\n",
      "25400 Average loss in the last 200 batches is 8339.986328125\n",
      "25600 Average loss in the last 200 batches is 8275.7451171875\n",
      "25800 Average loss in the last 200 batches is 8290.634765625\n",
      "26000 Average loss in the last 200 batches is 8256.8583984375\n",
      "Printing sample predictions after 26000 batches in sentence_predictions.text\n",
      "26200 Average loss in the last 200 batches is 8348.1708984375\n",
      "26400 Average loss in the last 200 batches is 8243.8935546875\n",
      "26600 Average loss in the last 200 batches is 8248.8466796875\n",
      "26800 Average loss in the last 200 batches is 8371.630859375\n",
      "27000 Average loss in the last 200 batches is 8355.3310546875\n",
      "27200 Average loss in the last 200 batches is 8312.978515625\n",
      "27400 Average loss in the last 200 batches is 8279.9833984375\n",
      "27600 Average loss in the last 200 batches is 8350.5361328125\n",
      "27800 Average loss in the last 200 batches is 8269.9375\n",
      "28000 Average loss in the last 200 batches is 8324.2265625\n",
      "Printing sample predictions after 28000 batches in sentence_predictions.text\n",
      "28200 Average loss in the last 200 batches is 8296.4375\n",
      "28400 Average loss in the last 200 batches is 8293.705078125\n",
      "28600 Average loss in the last 200 batches is 8344.6865234375\n",
      "28800 Average loss in the last 200 batches is 8304.322265625\n",
      "29000 Average loss in the last 200 batches is 8258.3623046875\n",
      "29200 Average loss in the last 200 batches is 8371.0556640625\n",
      "29400 Average loss in the last 200 batches is 8299.8359375\n",
      "29600 Average loss in the last 200 batches is 8288.853515625\n",
      "29800 Average loss in the last 200 batches is 8234.6728515625\n",
      "30000 Average loss in the last 200 batches is 8278.3779296875\n",
      "Printing sample predictions after 30000 batches in sentence_predictions.text\n",
      "30200 Average loss in the last 200 batches is 8248.9169921875\n",
      "30400 Average loss in the last 200 batches is 8323.28515625\n",
      "30600 Average loss in the last 200 batches is 8315.0390625\n",
      "30800 Average loss in the last 200 batches is 8339.740234375\n",
      "31000 Average loss in the last 200 batches is 8334.302734375\n",
      "31200 Average loss in the last 200 batches is 8285.740234375\n",
      "31400 Average loss in the last 200 batches is 8248.669921875\n",
      "31600 Average loss in the last 200 batches is 8322.732421875\n",
      "31800 Average loss in the last 200 batches is 8287.0341796875\n",
      "32000 Average loss in the last 200 batches is 8283.8447265625\n",
      "Printing sample predictions after 32000 batches in sentence_predictions.text\n",
      "32200 Average loss in the last 200 batches is 8284.1044921875\n",
      "32400 Average loss in the last 200 batches is 8244.232421875\n",
      "32600 Average loss in the last 200 batches is 8277.7001953125\n",
      "32800 Average loss in the last 200 batches is 8195.427734375\n",
      "33000 Average loss in the last 200 batches is 8293.302734375\n",
      "33200 Average loss in the last 200 batches is 8203.224609375\n",
      "33400 Average loss in the last 200 batches is 8250.615234375\n",
      "33600 Average loss in the last 200 batches is 8231.2294921875\n",
      "33800 Average loss in the last 200 batches is 8253.2509765625\n",
      "34000 Average loss in the last 200 batches is 8264.92578125\n",
      "Printing sample predictions after 34000 batches in sentence_predictions.text\n",
      "34200 Average loss in the last 200 batches is 8318.8671875\n",
      "34400 Average loss in the last 200 batches is 8296.037109375\n",
      "34600 Average loss in the last 200 batches is 8194.7919921875\n",
      "34800 Average loss in the last 200 batches is 8252.896484375\n",
      "35000 Average loss in the last 200 batches is 8226.134765625\n",
      "35200 Average loss in the last 200 batches is 8209.724609375\n",
      "35400 Average loss in the last 200 batches is 8213.265625\n",
      "35600 Average loss in the last 200 batches is 8231.7265625\n",
      "35800 Average loss in the last 200 batches is 8273.61328125\n",
      "36000 Average loss in the last 200 batches is 8284.015625\n",
      "Printing sample predictions after 36000 batches in sentence_predictions.text\n",
      "36200 Average loss in the last 200 batches is 8207.291015625\n",
      "36400 Average loss in the last 200 batches is 8258.5400390625\n",
      "36600 Average loss in the last 200 batches is 8270.0966796875\n",
      "36800 Average loss in the last 200 batches is 8129.73046875\n",
      "37000 Average loss in the last 200 batches is 8179.74609375\n",
      "37200 Average loss in the last 200 batches is 8224.1357421875\n",
      "37400 Average loss in the last 200 batches is 8257.0244140625\n",
      "37600 Average loss in the last 200 batches is 8182.73681640625\n",
      "37800 Average loss in the last 200 batches is 8300.6005859375\n",
      "38000 Average loss in the last 200 batches is 8248.849609375\n",
      "Printing sample predictions after 38000 batches in sentence_predictions.text\n",
      "38200 Average loss in the last 200 batches is 8162.12060546875\n",
      "38400 Average loss in the last 200 batches is 8193.2626953125\n",
      "38600 Average loss in the last 200 batches is 8237.4365234375\n",
      "38800 Average loss in the last 200 batches is 8267.6630859375\n",
      "39000 Average loss in the last 200 batches is 8277.6962890625\n",
      "39200 Average loss in the last 200 batches is 8232.146484375\n",
      "39400 Average loss in the last 200 batches is 8207.263671875\n",
      "39600 Average loss in the last 200 batches is 8247.27734375\n",
      "39800 Average loss in the last 200 batches is 8187.57958984375\n",
      "40000 Average loss in the last 200 batches is 8185.15234375\n",
      "Printing sample predictions after 40000 batches in sentence_predictions.text\n",
      "40200 Average loss in the last 200 batches is 8250.2705078125\n",
      "40400 Average loss in the last 200 batches is 8200.9052734375\n",
      "40600 Average loss in the last 200 batches is 8259.9169921875\n",
      "40800 Average loss in the last 200 batches is 8232.6572265625\n",
      "41000 Average loss in the last 200 batches is 8293.5029296875\n",
      "41200 Average loss in the last 200 batches is 8300.150390625\n",
      "41400 Average loss in the last 200 batches is 8184.37060546875\n",
      "41600 Average loss in the last 200 batches is 8194.6220703125\n",
      "41800 Average loss in the last 200 batches is 8216.71875\n",
      "42000 Average loss in the last 200 batches is 8229.39453125\n",
      "Printing sample predictions after 42000 batches in sentence_predictions.text\n",
      "42200 Average loss in the last 200 batches is 8218.9970703125\n",
      "42400 Average loss in the last 200 batches is 8225.6494140625\n",
      "42600 Average loss in the last 200 batches is 8200.1611328125\n",
      "42800 Average loss in the last 200 batches is 8280.298828125\n",
      "43000 Average loss in the last 200 batches is 8288.646484375\n",
      "43200 Average loss in the last 200 batches is 8196.544921875\n",
      "43400 Average loss in the last 200 batches is 8235.7138671875\n",
      "43600 Average loss in the last 200 batches is 8254.2177734375\n",
      "43800 Average loss in the last 200 batches is 8167.92578125\n",
      "44000 Average loss in the last 200 batches is 8195.8681640625\n",
      "Printing sample predictions after 44000 batches in sentence_predictions.text\n",
      "44200 Average loss in the last 200 batches is 8152.125\n",
      "44400 Average loss in the last 200 batches is 8175.138671875\n",
      "44600 Average loss in the last 200 batches is 8139.857421875\n",
      "44800 Average loss in the last 200 batches is 8258.05859375\n",
      "45000 Average loss in the last 200 batches is 8123.3369140625\n",
      "45200 Average loss in the last 200 batches is 8140.734375\n",
      "45400 Average loss in the last 200 batches is 8174.27880859375\n",
      "45600 Average loss in the last 200 batches is 8125.41064453125\n",
      "45800 Average loss in the last 200 batches is 8231.5908203125\n",
      "46000 Average loss in the last 200 batches is 8221.5234375\n",
      "Printing sample predictions after 46000 batches in sentence_predictions.text\n",
      "46200 Average loss in the last 200 batches is 8244.787109375\n",
      "46400 Average loss in the last 200 batches is 8187.96044921875\n",
      "46600 Average loss in the last 200 batches is 8199.1884765625\n",
      "46800 Average loss in the last 200 batches is 8216.4306640625\n",
      "47000 Average loss in the last 200 batches is 8244.990234375\n",
      "47200 Average loss in the last 200 batches is 8269.5830078125\n",
      "47400 Average loss in the last 200 batches is 8219.3720703125\n",
      "47600 Average loss in the last 200 batches is 8138.02490234375\n",
      "47800 Average loss in the last 200 batches is 8252.47265625\n",
      "48000 Average loss in the last 200 batches is 8155.2998046875\n",
      "Printing sample predictions after 48000 batches in sentence_predictions.text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48200 Average loss in the last 200 batches is 8235.7060546875\n",
      "48400 Average loss in the last 200 batches is 8270.7548828125\n",
      "48600 Average loss in the last 200 batches is 8172.2841796875\n",
      "48800 Average loss in the last 200 batches is 8102.3662109375\n",
      "49000 Average loss in the last 200 batches is 8226.0166015625\n",
      "49200 Average loss in the last 200 batches is 8129.18505859375\n",
      "49400 Average loss in the last 200 batches is 8098.24169921875\n",
      "49600 Average loss in the last 200 batches is 8113.24267578125\n",
      "49800 Average loss in the last 200 batches is 8169.158203125\n",
      "50000 Average loss in the last 200 batches is 8105.26416015625\n",
      "Printing sample predictions after 50000 batches in sentence_predictions.text\n",
      "50200 Average loss in the last 200 batches is 8191.80810546875\n",
      "50400 Average loss in the last 200 batches is 8160.361328125\n",
      "50600 Average loss in the last 200 batches is 8176.326171875\n",
      "50800 Average loss in the last 200 batches is 8247.390625\n",
      "51000 Average loss in the last 200 batches is 8169.93310546875\n",
      "51200 Average loss in the last 200 batches is 8139.4970703125\n",
      "51400 Average loss in the last 200 batches is 8117.6044921875\n",
      "51600 Average loss in the last 200 batches is 8167.091796875\n",
      "51800 Average loss in the last 200 batches is 8131.2412109375\n",
      "52000 Average loss in the last 200 batches is 8203.1787109375\n",
      "Printing sample predictions after 52000 batches in sentence_predictions.text\n",
      "52200 Average loss in the last 200 batches is 8136.85009765625\n",
      "52400 Average loss in the last 200 batches is 8121.66796875\n",
      "52600 Average loss in the last 200 batches is 8164.78564453125\n",
      "52800 Average loss in the last 200 batches is 8154.837890625\n",
      "53000 Average loss in the last 200 batches is 8176.9560546875\n",
      "53200 Average loss in the last 200 batches is 8135.60107421875\n",
      "53400 Average loss in the last 200 batches is 8054.30322265625\n",
      "53600 Average loss in the last 200 batches is 8087.16552734375\n",
      "53800 Average loss in the last 200 batches is 8164.13818359375\n",
      "54000 Average loss in the last 200 batches is 8152.400390625\n",
      "Printing sample predictions after 54000 batches in sentence_predictions.text\n",
      "54200 Average loss in the last 200 batches is 8197.6435546875\n",
      "54400 Average loss in the last 200 batches is 8100.32568359375\n",
      "54600 Average loss in the last 200 batches is 8121.8642578125\n",
      "54800 Average loss in the last 200 batches is 8097.4599609375\n",
      "55000 Average loss in the last 200 batches is 8102.9404296875\n",
      "55200 Average loss in the last 200 batches is 8175.54931640625\n",
      "55400 Average loss in the last 200 batches is 8096.64501953125\n",
      "55600 Average loss in the last 200 batches is 8125.0048828125\n",
      "55800 Average loss in the last 200 batches is 8174.45263671875\n",
      "56000 Average loss in the last 200 batches is 8104.20947265625\n",
      "Printing sample predictions after 56000 batches in sentence_predictions.text\n",
      "56200 Average loss in the last 200 batches is 8162.00732421875\n",
      "56400 Average loss in the last 200 batches is 8168.484375\n",
      "56600 Average loss in the last 200 batches is 8121.806640625\n",
      "56800 Average loss in the last 200 batches is 8154.5595703125\n",
      "57000 Average loss in the last 200 batches is 8191.76171875\n",
      "57200 Average loss in the last 200 batches is 8151.388671875\n",
      "57400 Average loss in the last 200 batches is 8136.900390625\n",
      "57600 Average loss in the last 200 batches is 8091.53125\n",
      "57800 Average loss in the last 200 batches is 8215.0576171875\n",
      "58000 Average loss in the last 200 batches is 8122.33251953125\n",
      "Printing sample predictions after 58000 batches in sentence_predictions.text\n",
      "58200 Average loss in the last 200 batches is 8110.0087890625\n",
      "58400 Average loss in the last 200 batches is 8152.2783203125\n",
      "58600 Average loss in the last 200 batches is 8145.02294921875\n",
      "58800 Average loss in the last 200 batches is 8051.86376953125\n",
      "59000 Average loss in the last 200 batches is 8166.2685546875\n",
      "59200 Average loss in the last 200 batches is 8101.47314453125\n",
      "59400 Average loss in the last 200 batches is 8069.623046875\n",
      "59600 Average loss in the last 200 batches is 8106.83544921875\n",
      "59800 Average loss in the last 200 batches is 8167.798828125\n",
      "60000 Average loss in the last 200 batches is 8148.60107421875\n",
      "Printing sample predictions after 60000 batches in sentence_predictions.text\n",
      "60200 Average loss in the last 200 batches is 8157.57568359375\n",
      "60400 Average loss in the last 200 batches is 8125.98291015625\n",
      "60600 Average loss in the last 200 batches is 8112.91015625\n",
      "60800 Average loss in the last 200 batches is 8159.83642578125\n",
      "61000 Average loss in the last 200 batches is 8173.6064453125\n",
      "61200 Average loss in the last 200 batches is 7997.650390625\n",
      "61400 Average loss in the last 200 batches is 8053.32958984375\n",
      "61600 Average loss in the last 200 batches is 8101.23046875\n",
      "61800 Average loss in the last 200 batches is 8132.07080078125\n",
      "62000 Average loss in the last 200 batches is 8184.83056640625\n",
      "Printing sample predictions after 62000 batches in sentence_predictions.text\n",
      "62200 Average loss in the last 200 batches is 8077.03125\n",
      "62400 Average loss in the last 200 batches is 8055.447265625\n",
      "62600 Average loss in the last 200 batches is 8131.986328125\n",
      "62800 Average loss in the last 200 batches is 8122.2431640625\n",
      "63000 Average loss in the last 200 batches is 8105.857421875\n",
      "63200 Average loss in the last 200 batches is 8035.064453125\n",
      "63400 Average loss in the last 200 batches is 8081.796875\n",
      "63600 Average loss in the last 200 batches is 8051.44677734375\n",
      "63800 Average loss in the last 200 batches is 8034.37548828125\n",
      "64000 Average loss in the last 200 batches is 8075.59375\n",
      "Printing sample predictions after 64000 batches in sentence_predictions.text\n",
      "64200 Average loss in the last 200 batches is 8068.10205078125\n",
      "64400 Average loss in the last 200 batches is 8062.79833984375\n",
      "64600 Average loss in the last 200 batches is 8130.51513671875\n",
      "64800 Average loss in the last 200 batches is 8144.78369140625\n",
      "65000 Average loss in the last 200 batches is 8082.3837890625\n",
      "65200 Average loss in the last 200 batches is 8072.5693359375\n",
      "65400 Average loss in the last 200 batches is 8057.90673828125\n",
      "65600 Average loss in the last 200 batches is 8122.26708984375\n",
      "65800 Average loss in the last 200 batches is 8080.44140625\n",
      "66000 Average loss in the last 200 batches is 8096.53076171875\n",
      "Printing sample predictions after 66000 batches in sentence_predictions.text\n",
      "66200 Average loss in the last 200 batches is 7992.11328125\n",
      "66400 Average loss in the last 200 batches is 7997.23876953125\n",
      "66600 Average loss in the last 200 batches is 8149.7314453125\n",
      "66800 Average loss in the last 200 batches is 8058.58544921875\n",
      "67000 Average loss in the last 200 batches is 8150.7001953125\n",
      "67200 Average loss in the last 200 batches is 8065.46484375\n",
      "67400 Average loss in the last 200 batches is 8103.04052734375\n",
      "67600 Average loss in the last 200 batches is 8087.25048828125\n",
      "67800 Average loss in the last 200 batches is 8111.3154296875\n",
      "68000 Average loss in the last 200 batches is 8188.86669921875\n",
      "Printing sample predictions after 68000 batches in sentence_predictions.text\n",
      "68200 Average loss in the last 200 batches is 8073.00830078125\n",
      "68400 Average loss in the last 200 batches is 8104.755859375\n",
      "68600 Average loss in the last 200 batches is 8091.60498046875\n",
      "68800 Average loss in the last 200 batches is 8081.34228515625\n",
      "69000 Average loss in the last 200 batches is 8064.337890625\n",
      "69200 Average loss in the last 200 batches is 8142.478515625\n",
      "69400 Average loss in the last 200 batches is 8075.39208984375\n",
      "69600 Average loss in the last 200 batches is 8077.40576171875\n",
      "69800 Average loss in the last 200 batches is 8077.02490234375\n",
      "Starting epoch 1 =====================\n",
      "70000 Average loss in the last 200 batches is 7042.74755859375\n",
      "Printing sample predictions after 70000 batches in sentence_predictions.text\n",
      "70200 Average loss in the last 200 batches is 7958.83544921875\n",
      "70400 Average loss in the last 200 batches is 7978.59765625\n",
      "70600 Average loss in the last 200 batches is 7957.7939453125\n",
      "70800 Average loss in the last 200 batches is 7979.775390625\n",
      "71000 Average loss in the last 200 batches is 7920.34814453125\n",
      "71200 Average loss in the last 200 batches is 7951.623046875\n",
      "71400 Average loss in the last 200 batches is 7987.15478515625\n",
      "71600 Average loss in the last 200 batches is 8006.369140625\n",
      "71800 Average loss in the last 200 batches is 8006.9970703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000 Average loss in the last 200 batches is 7997.4599609375\n",
      "Printing sample predictions after 72000 batches in sentence_predictions.text\n",
      "72200 Average loss in the last 200 batches is 7994.53564453125\n",
      "72400 Average loss in the last 200 batches is 7931.41943359375\n",
      "72600 Average loss in the last 200 batches is 8029.2060546875\n",
      "72800 Average loss in the last 200 batches is 7958.47119140625\n",
      "73000 Average loss in the last 200 batches is 7941.45458984375\n",
      "73200 Average loss in the last 200 batches is 7940.62890625\n",
      "73400 Average loss in the last 200 batches is 7982.12744140625\n",
      "73600 Average loss in the last 200 batches is 7947.412109375\n",
      "73800 Average loss in the last 200 batches is 7990.07421875\n",
      "74000 Average loss in the last 200 batches is 8023.21630859375\n",
      "Printing sample predictions after 74000 batches in sentence_predictions.text\n",
      "74200 Average loss in the last 200 batches is 7894.0263671875\n",
      "74400 Average loss in the last 200 batches is 8054.64013671875\n",
      "74600 Average loss in the last 200 batches is 7994.49267578125\n",
      "74800 Average loss in the last 200 batches is 7904.63134765625\n",
      "75000 Average loss in the last 200 batches is 8013.220703125\n",
      "75200 Average loss in the last 200 batches is 7978.01708984375\n",
      "75400 Average loss in the last 200 batches is 7975.0400390625\n",
      "75600 Average loss in the last 200 batches is 7975.57421875\n",
      "75800 Average loss in the last 200 batches is 7960.50830078125\n",
      "76000 Average loss in the last 200 batches is 8071.25\n",
      "Printing sample predictions after 76000 batches in sentence_predictions.text\n",
      "76200 Average loss in the last 200 batches is 7988.2255859375\n",
      "76400 Average loss in the last 200 batches is 7868.3017578125\n",
      "76600 Average loss in the last 200 batches is 7909.1455078125\n",
      "76800 Average loss in the last 200 batches is 8080.91796875\n",
      "77000 Average loss in the last 200 batches is 8043.09375\n",
      "77200 Average loss in the last 200 batches is 8034.49267578125\n",
      "77400 Average loss in the last 200 batches is 7914.015625\n",
      "77600 Average loss in the last 200 batches is 8012.93798828125\n",
      "77800 Average loss in the last 200 batches is 7945.2607421875\n",
      "78000 Average loss in the last 200 batches is 7971.60791015625\n",
      "Printing sample predictions after 78000 batches in sentence_predictions.text\n",
      "78200 Average loss in the last 200 batches is 7922.439453125\n",
      "78400 Average loss in the last 200 batches is 7892.1337890625\n",
      "78600 Average loss in the last 200 batches is 7992.7373046875\n",
      "78800 Average loss in the last 200 batches is 7923.16455078125\n",
      "79000 Average loss in the last 200 batches is 7902.31884765625\n",
      "79200 Average loss in the last 200 batches is 8024.05078125\n",
      "79400 Average loss in the last 200 batches is 7929.27001953125\n",
      "79600 Average loss in the last 200 batches is 7987.39501953125\n",
      "79800 Average loss in the last 200 batches is 7941.17919921875\n",
      "80000 Average loss in the last 200 batches is 7935.25146484375\n",
      "Printing sample predictions after 80000 batches in sentence_predictions.text\n",
      "80200 Average loss in the last 200 batches is 8011.55419921875\n",
      "80400 Average loss in the last 200 batches is 8045.38623046875\n",
      "80600 Average loss in the last 200 batches is 7939.9814453125\n",
      "80800 Average loss in the last 200 batches is 8094.50390625\n",
      "81000 Average loss in the last 200 batches is 8010.28125\n",
      "81200 Average loss in the last 200 batches is 8027.2412109375\n",
      "81400 Average loss in the last 200 batches is 8026.220703125\n",
      "81600 Average loss in the last 200 batches is 7930.9638671875\n",
      "81800 Average loss in the last 200 batches is 7947.830078125\n",
      "82000 Average loss in the last 200 batches is 7956.14453125\n",
      "Printing sample predictions after 82000 batches in sentence_predictions.text\n",
      "82200 Average loss in the last 200 batches is 8007.21728515625\n",
      "82400 Average loss in the last 200 batches is 8004.1025390625\n",
      "82600 Average loss in the last 200 batches is 7964.748046875\n",
      "82800 Average loss in the last 200 batches is 7909.046875\n",
      "83000 Average loss in the last 200 batches is 7886.84375\n",
      "83200 Average loss in the last 200 batches is 7976.251953125\n",
      "83400 Average loss in the last 200 batches is 8024.38427734375\n",
      "83600 Average loss in the last 200 batches is 7905.46826171875\n",
      "83800 Average loss in the last 200 batches is 7936.69189453125\n",
      "84000 Average loss in the last 200 batches is 7960.30078125\n",
      "Printing sample predictions after 84000 batches in sentence_predictions.text\n",
      "84200 Average loss in the last 200 batches is 7989.095703125\n",
      "84400 Average loss in the last 200 batches is 7955.1455078125\n",
      "84600 Average loss in the last 200 batches is 8025.50390625\n",
      "84800 Average loss in the last 200 batches is 7973.4580078125\n",
      "85000 Average loss in the last 200 batches is 7939.90869140625\n",
      "85200 Average loss in the last 200 batches is 7922.978515625\n",
      "85400 Average loss in the last 200 batches is 7965.12890625\n",
      "85600 Average loss in the last 200 batches is 7970.34423828125\n",
      "85800 Average loss in the last 200 batches is 7969.63623046875\n",
      "86000 Average loss in the last 200 batches is 7891.830078125\n",
      "Printing sample predictions after 86000 batches in sentence_predictions.text\n",
      "86200 Average loss in the last 200 batches is 7929.81201171875\n",
      "86400 Average loss in the last 200 batches is 8000.60693359375\n",
      "86600 Average loss in the last 200 batches is 7982.82421875\n",
      "86800 Average loss in the last 200 batches is 7898.35302734375\n",
      "87000 Average loss in the last 200 batches is 7979.9189453125\n",
      "87200 Average loss in the last 200 batches is 7997.544921875\n",
      "87400 Average loss in the last 200 batches is 7962.001953125\n",
      "87600 Average loss in the last 200 batches is 7981.34375\n",
      "87800 Average loss in the last 200 batches is 7926.54052734375\n",
      "88000 Average loss in the last 200 batches is 7989.5048828125\n",
      "Printing sample predictions after 88000 batches in sentence_predictions.text\n",
      "88200 Average loss in the last 200 batches is 7937.693359375\n",
      "88400 Average loss in the last 200 batches is 8002.1904296875\n",
      "88600 Average loss in the last 200 batches is 7935.927734375\n",
      "88800 Average loss in the last 200 batches is 8028.90673828125\n",
      "89000 Average loss in the last 200 batches is 7916.54541015625\n",
      "89200 Average loss in the last 200 batches is 7994.8251953125\n",
      "89400 Average loss in the last 200 batches is 7911.01708984375\n",
      "89600 Average loss in the last 200 batches is 7956.31689453125\n",
      "89800 Average loss in the last 200 batches is 7963.57421875\n",
      "90000 Average loss in the last 200 batches is 8026.18994140625\n",
      "Printing sample predictions after 90000 batches in sentence_predictions.text\n",
      "90200 Average loss in the last 200 batches is 8005.14306640625\n",
      "90400 Average loss in the last 200 batches is 7882.47705078125\n",
      "90600 Average loss in the last 200 batches is 7948.66455078125\n",
      "90800 Average loss in the last 200 batches is 7913.43701171875\n",
      "91000 Average loss in the last 200 batches is 7972.087890625\n",
      "91200 Average loss in the last 200 batches is 7949.4404296875\n",
      "91400 Average loss in the last 200 batches is 7953.21044921875\n",
      "91600 Average loss in the last 200 batches is 7958.904296875\n",
      "91800 Average loss in the last 200 batches is 7973.4130859375\n",
      "92000 Average loss in the last 200 batches is 7950.84521484375\n",
      "Printing sample predictions after 92000 batches in sentence_predictions.text\n",
      "92200 Average loss in the last 200 batches is 7967.0908203125\n",
      "92400 Average loss in the last 200 batches is 7969.9423828125\n",
      "92600 Average loss in the last 200 batches is 7908.39892578125\n",
      "92800 Average loss in the last 200 batches is 8042.38330078125\n",
      "93000 Average loss in the last 200 batches is 7878.50146484375\n",
      "93200 Average loss in the last 200 batches is 7947.482421875\n",
      "93400 Average loss in the last 200 batches is 7966.6494140625\n",
      "93600 Average loss in the last 200 batches is 8007.71044921875\n",
      "93800 Average loss in the last 200 batches is 7924.44140625\n",
      "94000 Average loss in the last 200 batches is 8015.861328125\n",
      "Printing sample predictions after 94000 batches in sentence_predictions.text\n",
      "94200 Average loss in the last 200 batches is 7894.43505859375\n",
      "94400 Average loss in the last 200 batches is 7972.14501953125\n",
      "94600 Average loss in the last 200 batches is 8003.5224609375\n",
      "94800 Average loss in the last 200 batches is 8045.361328125\n",
      "95000 Average loss in the last 200 batches is 7882.02490234375\n",
      "95200 Average loss in the last 200 batches is 7959.97509765625\n",
      "95400 Average loss in the last 200 batches is 7980.52734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95600 Average loss in the last 200 batches is 7967.630859375\n",
      "95800 Average loss in the last 200 batches is 7866.36767578125\n",
      "96000 Average loss in the last 200 batches is 7963.55126953125\n",
      "Printing sample predictions after 96000 batches in sentence_predictions.text\n",
      "96200 Average loss in the last 200 batches is 7976.87255859375\n",
      "96400 Average loss in the last 200 batches is 7958.7841796875\n",
      "96600 Average loss in the last 200 batches is 7919.865234375\n",
      "96800 Average loss in the last 200 batches is 7945.3486328125\n",
      "97000 Average loss in the last 200 batches is 7975.392578125\n",
      "97200 Average loss in the last 200 batches is 7980.22265625\n",
      "97400 Average loss in the last 200 batches is 7927.1513671875\n",
      "97600 Average loss in the last 200 batches is 7968.25\n",
      "97800 Average loss in the last 200 batches is 7982.466796875\n",
      "98000 Average loss in the last 200 batches is 8093.2158203125\n",
      "Printing sample predictions after 98000 batches in sentence_predictions.text\n",
      "98200 Average loss in the last 200 batches is 7909.2568359375\n",
      "98400 Average loss in the last 200 batches is 7948.52197265625\n",
      "98600 Average loss in the last 200 batches is 8003.990234375\n",
      "98800 Average loss in the last 200 batches is 7907.9892578125\n",
      "99000 Average loss in the last 200 batches is 7893.486328125\n",
      "99200 Average loss in the last 200 batches is 7919.4638671875\n",
      "99400 Average loss in the last 200 batches is 7945.353515625\n",
      "99600 Average loss in the last 200 batches is 7964.908203125\n",
      "99800 Average loss in the last 200 batches is 7996.0205078125\n",
      "100000 Average loss in the last 200 batches is 7911.08056640625\n",
      "Printing sample predictions after 100000 batches in sentence_predictions.text\n",
      "100200 Average loss in the last 200 batches is 7874.5732421875\n",
      "100400 Average loss in the last 200 batches is 7890.310546875\n",
      "100600 Average loss in the last 200 batches is 7877.51123046875\n",
      "100800 Average loss in the last 200 batches is 7996.78955078125\n",
      "101000 Average loss in the last 200 batches is 7915.41748046875\n",
      "101200 Average loss in the last 200 batches is 7986.89453125\n",
      "101400 Average loss in the last 200 batches is 7890.85107421875\n",
      "101600 Average loss in the last 200 batches is 7882.46142578125\n",
      "101800 Average loss in the last 200 batches is 7884.34228515625\n",
      "102000 Average loss in the last 200 batches is 7882.97998046875\n",
      "Printing sample predictions after 102000 batches in sentence_predictions.text\n",
      "102200 Average loss in the last 200 batches is 7920.74072265625\n",
      "102400 Average loss in the last 200 batches is 7890.58203125\n",
      "102600 Average loss in the last 200 batches is 7881.828125\n",
      "102800 Average loss in the last 200 batches is 7910.6806640625\n",
      "103000 Average loss in the last 200 batches is 7879.33251953125\n",
      "103200 Average loss in the last 200 batches is 7936.08544921875\n",
      "103400 Average loss in the last 200 batches is 7929.33642578125\n",
      "103600 Average loss in the last 200 batches is 7897.5810546875\n",
      "103800 Average loss in the last 200 batches is 7870.75732421875\n",
      "104000 Average loss in the last 200 batches is 7923.8388671875\n",
      "Printing sample predictions after 104000 batches in sentence_predictions.text\n",
      "104200 Average loss in the last 200 batches is 7841.9091796875\n",
      "104400 Average loss in the last 200 batches is 7940.3505859375\n",
      "104600 Average loss in the last 200 batches is 7908.41357421875\n",
      "104800 Average loss in the last 200 batches is 7958.263671875\n",
      "105000 Average loss in the last 200 batches is 7870.5126953125\n",
      "105200 Average loss in the last 200 batches is 7959.57568359375\n",
      "105400 Average loss in the last 200 batches is 7971.99951171875\n",
      "105600 Average loss in the last 200 batches is 7932.5966796875\n",
      "105800 Average loss in the last 200 batches is 7939.0556640625\n",
      "106000 Average loss in the last 200 batches is 7862.66552734375\n",
      "Printing sample predictions after 106000 batches in sentence_predictions.text\n",
      "106200 Average loss in the last 200 batches is 7883.06396484375\n",
      "106400 Average loss in the last 200 batches is 8002.58056640625\n",
      "106600 Average loss in the last 200 batches is 7922.6474609375\n",
      "106800 Average loss in the last 200 batches is 7914.99853515625\n",
      "107000 Average loss in the last 200 batches is 7922.18701171875\n",
      "107200 Average loss in the last 200 batches is 7883.298828125\n",
      "107400 Average loss in the last 200 batches is 7915.49609375\n",
      "107600 Average loss in the last 200 batches is 7902.568359375\n",
      "107800 Average loss in the last 200 batches is 7949.66552734375\n",
      "108000 Average loss in the last 200 batches is 7970.53515625\n",
      "Printing sample predictions after 108000 batches in sentence_predictions.text\n",
      "108200 Average loss in the last 200 batches is 7982.82177734375\n",
      "108400 Average loss in the last 200 batches is 7845.375\n",
      "108600 Average loss in the last 200 batches is 7884.35302734375\n",
      "108800 Average loss in the last 200 batches is 7912.154296875\n",
      "109000 Average loss in the last 200 batches is 7913.03955078125\n",
      "109200 Average loss in the last 200 batches is 7897.71435546875\n",
      "109400 Average loss in the last 200 batches is 7962.861328125\n",
      "109600 Average loss in the last 200 batches is 7916.669921875\n",
      "109800 Average loss in the last 200 batches is 7906.66748046875\n",
      "110000 Average loss in the last 200 batches is 7859.765625\n",
      "Printing sample predictions after 110000 batches in sentence_predictions.text\n",
      "110200 Average loss in the last 200 batches is 7909.234375\n",
      "110400 Average loss in the last 200 batches is 7861.41064453125\n",
      "110600 Average loss in the last 200 batches is 7957.83203125\n",
      "110800 Average loss in the last 200 batches is 7891.05322265625\n",
      "111000 Average loss in the last 200 batches is 7900.75927734375\n",
      "111200 Average loss in the last 200 batches is 7921.8056640625\n",
      "111400 Average loss in the last 200 batches is 7976.46630859375\n",
      "111600 Average loss in the last 200 batches is 7891.12451171875\n",
      "111800 Average loss in the last 200 batches is 7966.26806640625\n",
      "112000 Average loss in the last 200 batches is 7870.9326171875\n",
      "Printing sample predictions after 112000 batches in sentence_predictions.text\n",
      "112200 Average loss in the last 200 batches is 7957.3994140625\n",
      "112400 Average loss in the last 200 batches is 7835.72705078125\n",
      "112600 Average loss in the last 200 batches is 7871.6591796875\n",
      "112800 Average loss in the last 200 batches is 7885.90625\n",
      "113000 Average loss in the last 200 batches is 7928.830078125\n",
      "113200 Average loss in the last 200 batches is 7932.97705078125\n",
      "113400 Average loss in the last 200 batches is 7884.81689453125\n",
      "113600 Average loss in the last 200 batches is 7911.56494140625\n",
      "113800 Average loss in the last 200 batches is 7882.15869140625\n",
      "114000 Average loss in the last 200 batches is 7878.1650390625\n",
      "Printing sample predictions after 114000 batches in sentence_predictions.text\n",
      "114200 Average loss in the last 200 batches is 7899.01611328125\n",
      "114400 Average loss in the last 200 batches is 7981.71875\n",
      "114600 Average loss in the last 200 batches is 7884.7685546875\n",
      "114800 Average loss in the last 200 batches is 7875.68896484375\n",
      "115000 Average loss in the last 200 batches is 7864.15869140625\n",
      "115200 Average loss in the last 200 batches is 7927.75439453125\n",
      "115400 Average loss in the last 200 batches is 7926.65234375\n",
      "115600 Average loss in the last 200 batches is 7873.52685546875\n",
      "115800 Average loss in the last 200 batches is 7858.0361328125\n",
      "116000 Average loss in the last 200 batches is 7819.04296875\n",
      "Printing sample predictions after 116000 batches in sentence_predictions.text\n",
      "116200 Average loss in the last 200 batches is 7859.388671875\n",
      "116400 Average loss in the last 200 batches is 7814.0673828125\n",
      "116600 Average loss in the last 200 batches is 7917.0185546875\n",
      "116800 Average loss in the last 200 batches is 7918.57373046875\n",
      "117000 Average loss in the last 200 batches is 7948.64501953125\n",
      "117200 Average loss in the last 200 batches is 7887.31689453125\n",
      "117400 Average loss in the last 200 batches is 7898.9873046875\n",
      "117600 Average loss in the last 200 batches is 7889.43994140625\n",
      "117800 Average loss in the last 200 batches is 7932.27197265625\n",
      "118000 Average loss in the last 200 batches is 7836.234375\n",
      "Printing sample predictions after 118000 batches in sentence_predictions.text\n",
      "118200 Average loss in the last 200 batches is 7825.91259765625\n",
      "118400 Average loss in the last 200 batches is 7885.2529296875\n",
      "118600 Average loss in the last 200 batches is 7945.220703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118800 Average loss in the last 200 batches is 7893.3935546875\n",
      "119000 Average loss in the last 200 batches is 7788.71875\n",
      "119200 Average loss in the last 200 batches is 7960.40576171875\n",
      "119400 Average loss in the last 200 batches is 7913.21435546875\n",
      "119600 Average loss in the last 200 batches is 7948.41259765625\n",
      "119800 Average loss in the last 200 batches is 7859.83544921875\n",
      "120000 Average loss in the last 200 batches is 7889.13427734375\n",
      "Printing sample predictions after 120000 batches in sentence_predictions.text\n",
      "120200 Average loss in the last 200 batches is 7874.4638671875\n",
      "120400 Average loss in the last 200 batches is 7910.6904296875\n",
      "120600 Average loss in the last 200 batches is 7818.14453125\n",
      "120800 Average loss in the last 200 batches is 7867.0419921875\n",
      "121000 Average loss in the last 200 batches is 7868.86767578125\n",
      "121200 Average loss in the last 200 batches is 7872.130859375\n",
      "121400 Average loss in the last 200 batches is 7891.10302734375\n",
      "121600 Average loss in the last 200 batches is 7857.67431640625\n",
      "121800 Average loss in the last 200 batches is 7943.05859375\n",
      "122000 Average loss in the last 200 batches is 7865.5888671875\n",
      "Printing sample predictions after 122000 batches in sentence_predictions.text\n",
      "122200 Average loss in the last 200 batches is 7821.22265625\n",
      "122400 Average loss in the last 200 batches is 7890.09765625\n",
      "122600 Average loss in the last 200 batches is 7858.8125\n",
      "122800 Average loss in the last 200 batches is 7836.75927734375\n",
      "123000 Average loss in the last 200 batches is 7913.34765625\n",
      "123200 Average loss in the last 200 batches is 7811.4658203125\n",
      "123400 Average loss in the last 200 batches is 7879.53564453125\n",
      "123600 Average loss in the last 200 batches is 7950.85009765625\n",
      "123800 Average loss in the last 200 batches is 7851.2998046875\n",
      "124000 Average loss in the last 200 batches is 7812.9892578125\n",
      "Printing sample predictions after 124000 batches in sentence_predictions.text\n",
      "124200 Average loss in the last 200 batches is 7885.8818359375\n",
      "124400 Average loss in the last 200 batches is 7857.2255859375\n",
      "124600 Average loss in the last 200 batches is 7929.5986328125\n",
      "124800 Average loss in the last 200 batches is 7814.7294921875\n",
      "125000 Average loss in the last 200 batches is 7863.81201171875\n",
      "125200 Average loss in the last 200 batches is 7891.7314453125\n",
      "125400 Average loss in the last 200 batches is 7779.9091796875\n",
      "125600 Average loss in the last 200 batches is 7859.91357421875\n",
      "125800 Average loss in the last 200 batches is 7918.423828125\n",
      "126000 Average loss in the last 200 batches is 7741.919921875\n",
      "Printing sample predictions after 126000 batches in sentence_predictions.text\n",
      "126200 Average loss in the last 200 batches is 7903.96435546875\n",
      "126400 Average loss in the last 200 batches is 7824.91748046875\n",
      "126600 Average loss in the last 200 batches is 7858.33935546875\n",
      "126800 Average loss in the last 200 batches is 7864.17578125\n",
      "127000 Average loss in the last 200 batches is 7776.20751953125\n",
      "127200 Average loss in the last 200 batches is 7919.32763671875\n",
      "127400 Average loss in the last 200 batches is 7905.3466796875\n",
      "127600 Average loss in the last 200 batches is 7757.48828125\n",
      "127800 Average loss in the last 200 batches is 7933.810546875\n",
      "128000 Average loss in the last 200 batches is 7899.9375\n",
      "Printing sample predictions after 128000 batches in sentence_predictions.text\n",
      "128200 Average loss in the last 200 batches is 7936.087890625\n",
      "128400 Average loss in the last 200 batches is 7904.6005859375\n",
      "128600 Average loss in the last 200 batches is 7812.55126953125\n",
      "128800 Average loss in the last 200 batches is 7929.33544921875\n",
      "129000 Average loss in the last 200 batches is 7839.09326171875\n",
      "129200 Average loss in the last 200 batches is 7842.6005859375\n",
      "129400 Average loss in the last 200 batches is 7909.58740234375\n",
      "129600 Average loss in the last 200 batches is 7851.86865234375\n",
      "129800 Average loss in the last 200 batches is 7875.40869140625\n",
      "130000 Average loss in the last 200 batches is 7889.798828125\n",
      "Printing sample predictions after 130000 batches in sentence_predictions.text\n",
      "130200 Average loss in the last 200 batches is 7881.19189453125\n",
      "130400 Average loss in the last 200 batches is 7879.67578125\n",
      "130600 Average loss in the last 200 batches is 7815.5888671875\n",
      "130800 Average loss in the last 200 batches is 7818.52978515625\n",
      "131000 Average loss in the last 200 batches is 7818.796875\n",
      "131200 Average loss in the last 200 batches is 7767.69921875\n",
      "131400 Average loss in the last 200 batches is 7908.892578125\n",
      "131600 Average loss in the last 200 batches is 7880.7099609375\n",
      "131800 Average loss in the last 200 batches is 7867.67431640625\n",
      "132000 Average loss in the last 200 batches is 7844.64111328125\n",
      "Printing sample predictions after 132000 batches in sentence_predictions.text\n",
      "132200 Average loss in the last 200 batches is 7840.98583984375\n",
      "132400 Average loss in the last 200 batches is 7886.9912109375\n",
      "132600 Average loss in the last 200 batches is 7796.64013671875\n",
      "132800 Average loss in the last 200 batches is 7805.91357421875\n",
      "133000 Average loss in the last 200 batches is 7858.18505859375\n",
      "133200 Average loss in the last 200 batches is 7932.50927734375\n",
      "133400 Average loss in the last 200 batches is 7906.90576171875\n",
      "133600 Average loss in the last 200 batches is 7864.96728515625\n",
      "133800 Average loss in the last 200 batches is 7849.0400390625\n",
      "134000 Average loss in the last 200 batches is 7838.451171875\n",
      "Printing sample predictions after 134000 batches in sentence_predictions.text\n",
      "134200 Average loss in the last 200 batches is 7828.87744140625\n",
      "134400 Average loss in the last 200 batches is 7825.57958984375\n",
      "134600 Average loss in the last 200 batches is 7923.708984375\n",
      "134800 Average loss in the last 200 batches is 7906.36376953125\n",
      "135000 Average loss in the last 200 batches is 7846.5205078125\n",
      "135200 Average loss in the last 200 batches is 7867.529296875\n",
      "135400 Average loss in the last 200 batches is 7799.39501953125\n",
      "135600 Average loss in the last 200 batches is 7874.16259765625\n",
      "135800 Average loss in the last 200 batches is 7866.12060546875\n",
      "136000 Average loss in the last 200 batches is 7849.337890625\n",
      "Printing sample predictions after 136000 batches in sentence_predictions.text\n",
      "136200 Average loss in the last 200 batches is 7815.3974609375\n",
      "136400 Average loss in the last 200 batches is 7884.392578125\n",
      "136600 Average loss in the last 200 batches is 7839.271484375\n",
      "136800 Average loss in the last 200 batches is 7902.861328125\n",
      "137000 Average loss in the last 200 batches is 7828.57666015625\n",
      "137200 Average loss in the last 200 batches is 7881.98486328125\n",
      "137400 Average loss in the last 200 batches is 7880.80126953125\n",
      "137600 Average loss in the last 200 batches is 7991.7431640625\n",
      "137800 Average loss in the last 200 batches is 7811.705078125\n",
      "138000 Average loss in the last 200 batches is 7740.11181640625\n",
      "Printing sample predictions after 138000 batches in sentence_predictions.text\n",
      "138200 Average loss in the last 200 batches is 7844.8076171875\n",
      "138400 Average loss in the last 200 batches is 7839.384765625\n",
      "138600 Average loss in the last 200 batches is 7931.40234375\n",
      "138800 Average loss in the last 200 batches is 7874.11181640625\n",
      "139000 Average loss in the last 200 batches is 7906.68896484375\n",
      "139200 Average loss in the last 200 batches is 7870.54443359375\n",
      "139400 Average loss in the last 200 batches is 7886.26806640625\n",
      "139600 Average loss in the last 200 batches is 7868.14208984375\n",
      "Starting epoch 2 =====================\n",
      "139800 Average loss in the last 200 batches is 5808.57373046875\n",
      "140000 Average loss in the last 200 batches is 7767.1943359375\n",
      "Printing sample predictions after 140000 batches in sentence_predictions.text\n",
      "140200 Average loss in the last 200 batches is 7697.38916015625\n",
      "140400 Average loss in the last 200 batches is 7733.42041015625\n",
      "140600 Average loss in the last 200 batches is 7762.587890625\n",
      "140800 Average loss in the last 200 batches is 7736.1298828125\n",
      "141000 Average loss in the last 200 batches is 7768.908203125\n",
      "141200 Average loss in the last 200 batches is 7781.75439453125\n",
      "141400 Average loss in the last 200 batches is 7805.69873046875\n",
      "141600 Average loss in the last 200 batches is 7678.03759765625\n",
      "141800 Average loss in the last 200 batches is 7776.4951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142000 Average loss in the last 200 batches is 7801.388671875\n",
      "Printing sample predictions after 142000 batches in sentence_predictions.text\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 =====================\n",
      "200 Average loss in the last 200 batches is 7711.92578125\n"
     ]
    }
   ],
   "source": [
    "#Continue with smaller learning rate. \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
